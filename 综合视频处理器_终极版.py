# _*_ coding: utf-8 _*_
"""
ç»¼åˆè§†é¢‘å¤„ç†å™¨ - ç»ˆæç‰ˆ
æ•´åˆè§†é¢‘è£å‰ªã€åˆ‡å¤´å°¾ã€æ™ºèƒ½ç¼“å­˜ã€æ•°æ®åº“å»é‡ç­‰æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½

ä½œè€…: L
ç‰ˆæœ¬: 3.0 Ultimate
åŠŸèƒ½: 
- è§†é¢‘è£å‰ª + ROIé€‰æ‹©
- è§†é¢‘åˆ‡å¤´å°¾å¤„ç†
- æ™ºèƒ½ç¼“å­˜ç®¡ç†
- æ•°æ®åº“å»é‡ç³»ç»Ÿ
- æµæ°´çº¿å¹¶è¡Œå¤„ç†
- ç¡¬ä»¶ä¼˜åŒ–åŠ é€Ÿ
- å¤šç”µè„‘åä½œ
"""

# ==================== ç”¨æˆ·é…ç½®åŒºåŸŸ ====================
# !!! è¯·æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ä»¥ä¸‹é…ç½® !!!

# --- FFmpeg è·¯å¾„é…ç½® ---
FFMPEG_PATH = r"D:\ffmpeg-master-latest-win64-gpl\ffmpeg-master-latest-win64-gpl\bin\ffmpeg.exe"
FFPROBE_PATH = r"D:\ffmpeg-master-latest-win64-gpl\ffmpeg-master-latest-win64-gpl\bin\ffprobe.exe"
# --- æ•°æ®åº“è®°å½•å­—æ®µé…ç½® ---
# !!! é‡è¦ï¼šæ¯æ¬¡è§†é¢‘å¤„ç†æˆåŠŸåï¼Œä»¥ä¸‹11ä¸ªå­—æ®µä¿¡æ¯ä¼šæ’å…¥Video_Editingè¡¨ !!!
OPERATOR_NAME = "L"                   # æ“ä½œäººå‘˜å§“å/ç”¨æˆ·å (å¿…å¡«)
COMPUTER_NAME = "å¤§09"                # ç”µè„‘åç§° (ç•™ç©ºåˆ™è‡ªåŠ¨è·å–å½“å‰ç”µè„‘å)
COMPUTER_IP = ""                      # ç”µè„‘IPåœ°å€ (ç•™ç©ºåˆ™è‡ªåŠ¨è·å–æœ¬æœºIP)
AUTO_GET_COMPUTER_INFO = True         # è‡ªåŠ¨è·å–ç”µè„‘ä¿¡æ¯(åç§°å’ŒIP)
# å…¶ä»–å­—æ®µç”±ç¨‹åºè‡ªåŠ¨ç”Ÿæˆï¼šinput_path, output_path, video_name, 
# pre_processing_size, resolution, hash_value, status, log_path
# --- è¾“å…¥è¾“å‡ºè·¯å¾„é…ç½® ---
INPUT_DIR = r"D:\ä¸€èˆ¬ç±»"
OUTPUT_DIR = r"D:\æµ‹è¯•å®Œ"
PROGRESS_FOLDER = r"Z:\personal_folder\L\å¤„ç†å®Œæ•°æ®è®°å½•"

# --- å¤„ç†æ¨¡å¼é…ç½® ---
PROCESSING_MODE = "both"  # "crop" = è£å‰ªæ¨¡å¼, "trim" = åˆ‡å¤´å°¾æ¨¡å¼, "both" = ä¸¤ç§éƒ½åš
TARGET_RESOLUTION = (1920, 1080)  # ç›®æ ‡åˆ†è¾¨ç‡ (ä»…è£å‰ªæ¨¡å¼)

# --- åˆ‡å¤´å°¾é…ç½® (ä»…åˆ‡å¤´å°¾æ¨¡å¼) ---
CUT_HEAD_SECONDS = 47     # åˆ‡æ‰å¼€å¤´ç§’æ•°
CUT_TAIL_SECONDS = 47      # åˆ‡æ‰ç»“å°¾ç§’æ•°
SEGMENT_DURATION = 0   # åˆ†æ®µæ—¶é•¿(ç§’), 0=ä¸åˆ†æ®µ

# --- æ™ºèƒ½ç¼“å­˜é…ç½® ---
ENABLE_CACHE = True                    # å¯ç”¨æ™ºèƒ½ç¼“å­˜
CACHE_DIR = r"D:\VideoCache"          # ç¼“å­˜ç›®å½•
MAX_CACHE_SIZE_GB = 500               # æœ€å¤§ç¼“å­˜å¤§å°(GB)
CACHE_CLEANUP_THRESHOLD = 0.9         # æ¸…ç†é˜ˆå€¼(90%)
PRELOAD_COUNT = 2                     # é¢„åŠ è½½è§†é¢‘æ•°é‡

# --- æ•°æ®åº“é…ç½® ---
ENABLE_DATABASE = True                # å¯ç”¨æ•°æ®åº“å»é‡
DB_HOST = "192.168.10.70"            # æ•°æ®åº“ä¸»æœº
DB_PORT = 3306                        # æ•°æ®åº“ç«¯å£
DB_NAME = "data_sql"                  # æ•°æ®åº“å
DB_USER = "root"                      # æ•°æ®åº“ç”¨æˆ·
DB_PASSWORD = "zq828079"              # æ•°æ®åº“å¯†ç 
TABLE_NAME = "Video_Editing"          # å›ºå®šè¡¨å



# --- æ€§èƒ½é…ç½® ---
MAX_PARALLEL_WORKERS = 6              # æœ€å¤§å¹¶è¡Œæ•°
QUALITY_MODE = 'highest'              # è´¨é‡æ¨¡å¼: 'highest' | 'high' | 'balanced' | 'fast'
AUTO_BITRATE = True                   # è‡ªåŠ¨ç ç‡è°ƒæ•´
VIDEO_BITRATE = "10M"                 # å›ºå®šç ç‡(AUTO_BITRATE=Falseæ—¶ä½¿ç”¨)

# --- é•¿æ—¶é—´å¤„ç†ç¨³å®šæ€§é…ç½® ---
MEMORY_CLEANUP_INTERVAL = 50          # æ¯å¤„ç†Nä¸ªè§†é¢‘æ¸…ç†ä¸€æ¬¡å†…å­˜
MAX_MEMORY_USAGE_MB = 8192            # æœ€å¤§å†…å­˜ä½¿ç”¨é‡(MB)ï¼Œè¶…è¿‡åˆ™å¼ºåˆ¶æ¸…ç†
HEARTBEAT_INTERVAL = 300              # å¿ƒè·³æ£€æµ‹é—´éš”(ç§’)
MAX_PROCESSING_TIME_HOURS = 24        # å•ä¸ªè§†é¢‘æœ€å¤§å¤„ç†æ—¶é—´(å°æ—¶)
ENABLE_WATCHDOG = True                # å¯ç”¨çœ‹é—¨ç‹—æœºåˆ¶
AUTO_RESTART_ON_ERROR = True          # é”™è¯¯æ—¶è‡ªåŠ¨é‡å¯
BATCH_SIZE = 100                      # åˆ†æ‰¹å¤„ç†å¤§å°ï¼Œå¤§æ•°æ®é›†åˆ†æ‰¹å¤„ç†

# --- å¤šç”µè„‘åä½œé…ç½® ---
ENABLE_DISTRIBUTED_PROCESSING = True  # å¯ç”¨åˆ†å¸ƒå¼å¤„ç†
COMPUTER_LOCK_TIMEOUT = 1800          # ç”µè„‘é”å®šè¶…æ—¶æ—¶é—´(ç§’)
TASK_CLAIM_RETRY_INTERVAL = 60        # ä»»åŠ¡å£°æ˜é‡è¯•é—´éš”(ç§’)
ENABLE_LOAD_BALANCING = True          # å¯ç”¨è´Ÿè½½å‡è¡¡

# --- ä½åˆ†è¾¨ç‡è·³è¿‡é…ç½® ---
SKIP_LOW_RESOLUTION = True            # è·³è¿‡ä½åˆ†è¾¨ç‡è§†é¢‘
MIN_RESOLUTION_WIDTH = 1920           # æœ€å°åˆ†è¾¨ç‡å®½åº¦
SKIP_VIDEOS_MOVE_DIR = r"Z:\personal_folder\L\è·³è¿‡çš„ä½åˆ†è¾¨ç‡è§†é¢‘"

# --- æ”¯æŒçš„è§†é¢‘æ ¼å¼ ---
SUPPORTED_VIDEO_FORMATS = ['.mp4', '.mov', '.avi', '.mkv', '.wmv', '.flv', '.webm', '.ts', '.m4v', '.3gp', '.f4v']

# --- å¤„ç†å™¨ä¿¡æ¯ ---
PROCESSOR_NAME = "ç»¼åˆè§†é¢‘å¤„ç†å™¨_ç»ˆæç‰ˆ"  # æ“ä½œå‘˜åç§°

# ==================== ä¾èµ–æ£€æŸ¥ ====================
def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–åº“"""
    required_packages = {
        'cv2': 'opencv-python',
        'numpy': 'numpy',
        'tqdm': 'tqdm',
        'psutil': 'psutil'
    }
    
    optional_packages = {
        'pymysql': 'pymysql'
    }
    
    missing_required = []
    missing_optional = []
    
    for module, package in required_packages.items():
        try:
            __import__(module)
        except ImportError:
            missing_required.append(package)
    
    for module, package in optional_packages.items():
        try:
            __import__(module)
        except ImportError:
            missing_optional.append(package)
    
    if missing_required:
        print("âŒ ç¼ºå°‘å¿…è¦ä¾èµ–åº“:")
        for package in missing_required:
            print(f"   - {package}")
        print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…:")
        print(f"pip install {' '.join(missing_required)}")
        return False
    
    if missing_optional:
        print("âš ï¸ ç¼ºå°‘å¯é€‰ä¾èµ–åº“ï¼ˆåŠŸèƒ½ä¼šè¢«ç¦ç”¨ï¼‰:")
        for package in missing_optional:
            print(f"   - {package}")
        print("\nè¦å¯ç”¨å®Œæ•´åŠŸèƒ½ï¼Œè¯·è¿è¡Œ:")
        print(f"pip install {' '.join(missing_optional)}")
    
    return True

# ==================== å¯¼å…¥æ¨¡å— ====================
# æ£€æŸ¥ä¾èµ–
if not check_dependencies():
    sys.exit(1)

import time
import cv2
import os
import sys
import json
import shutil
import logging
import hashlib
import sqlite3
import threading
import subprocess
import concurrent.futures
import multiprocessing
import platform
import socket
import uuid
import psutil
import pickle
import glob
import re
import signal
import traceback
import queue
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
from typing import List, Tuple, Dict, Optional, Any
from dataclasses import dataclass, field
from contextlib import contextmanager
import numpy as np
import enum

# ==================== æ—¥å¿—é…ç½® ====================
def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path('logs')
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / "unified_video_processor.log", encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    logging.getLogger('PIL').setLevel(logging.WARNING)
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    
    return logging.getLogger(__name__)

logger = setup_logging()

# ==================== æ ¸å¿ƒæ•°æ®ç»“æ„ ====================
class ProcessingMode(enum.Enum):
    """å¤„ç†æ¨¡å¼æšä¸¾"""
    CROP = "crop"
    TRIM = "trim"
    BOTH = "both"

class PipelineStage(enum.Enum):
    """æµæ°´çº¿é˜¶æ®µçŠ¶æ€"""
    PENDING = "pending"
    CACHING = "caching"
    CACHED = "cached"
    CHECKING = "checking"
    DUPLICATE = "duplicate"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"
    CANCELLED = "cancelled"

@dataclass
class VideoTask:
    """è§†é¢‘å¤„ç†ä»»åŠ¡"""
    video_path: str
    task_id: str
    mode: ProcessingMode
    stage: PipelineStage = PipelineStage.PENDING
    cache_path: Optional[str] = None
    hash_value: Optional[str] = None
    error_msg: Optional[str] = None
    retry_count: int = 0
    max_retries: int = 3
    created_time: float = field(default_factory=time.time)
    stage_start_time: float = field(default_factory=time.time)
    
    # ROIè®¾ç½® (è£å‰ªæ¨¡å¼)
    roi: Optional[Tuple[int, int, int, int]] = None
    
    # åˆ‡ç‰‡è®¾ç½® (åˆ‡å¤´å°¾æ¨¡å¼)
    cut_head: float = 0
    cut_tail: float = 0
    segment_duration: float = 0
    
    def update_stage(self, new_stage: PipelineStage, error_msg: str = None):
        """æ›´æ–°ä»»åŠ¡é˜¶æ®µ"""
        self.stage = new_stage
        self.stage_start_time = time.time()
        if error_msg:
            self.error_msg = error_msg
    
    def can_retry(self) -> bool:
        """æ˜¯å¦å¯ä»¥é‡è¯•"""
        return self.retry_count < self.max_retries
    
    def increment_retry(self):
        """å¢åŠ é‡è¯•æ¬¡æ•°"""
        self.retry_count += 1

# ==================== å†…å­˜å’Œå¥åº·ç›‘æ§å™¨ ====================
class MemoryHealthMonitor:
    """å†…å­˜å¥åº·ç›‘æ§å™¨ - é•¿æ—¶é—´å¤„ç†ç¨³å®šæ€§ä¿éšœ"""
    
    def __init__(self):
        self.start_time = time.time()
        self.last_cleanup_time = time.time()
        self.processed_count = 0
        self.memory_samples = []
        self.max_memory_seen = 0
        self.cleanup_count = 0
        
    def should_cleanup_memory(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†å†…å­˜"""
        try:
            import psutil
            process = psutil.Process()
            memory_mb = process.memory_info().rss / 1024 / 1024
            self.max_memory_seen = max(self.max_memory_seen, memory_mb)
            
            # è®°å½•å†…å­˜æ ·æœ¬
            if len(self.memory_samples) >= 100:
                self.memory_samples.pop(0)
            self.memory_samples.append(memory_mb)
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡å†…å­˜é˜ˆå€¼
            if memory_mb > MAX_MEMORY_USAGE_MB:
                logger.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨è¶…é™: {memory_mb:.1f}MB > {MAX_MEMORY_USAGE_MB}MB")
                return True
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å®šæœŸæ¸…ç†é—´éš”
            if self.processed_count % MEMORY_CLEANUP_INTERVAL == 0 and self.processed_count > 0:
                return True
                
            return False
            
        except Exception as e:
            logger.warning(f"å†…å­˜æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def cleanup_memory(self, force: bool = False):
        """æ¸…ç†å†…å­˜"""
        try:
            import gc
            import psutil
            
            process = psutil.Process()
            before_mb = process.memory_info().rss / 1024 / 1024
            
            # æ‰§è¡Œåƒåœ¾å›æ”¶
            collected = gc.collect()
            
            # å¼ºåˆ¶æ¸…ç†æ—¶æ‰§è¡Œé¢å¤–æ“ä½œ
            if force:
                gc.collect()  # äºŒæ¬¡æ¸…ç†
                gc.collect()  # ä¸‰æ¬¡æ¸…ç†
                
            after_mb = process.memory_info().rss / 1024 / 1024
            freed_mb = before_mb - after_mb
            
            self.cleanup_count += 1
            self.last_cleanup_time = time.time()
            
            logger.info(f"ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆ #{self.cleanup_count}: {before_mb:.1f}MB â†’ {after_mb:.1f}MB "
                       f"(é‡Šæ”¾{freed_mb:.1f}MB, å›æ”¶{collected}ä¸ªå¯¹è±¡)")
            
            return freed_mb
            
        except Exception as e:
            logger.error(f"å†…å­˜æ¸…ç†å¤±è´¥: {e}")
            return 0
    
    def update_processed_count(self):
        """æ›´æ–°å¤„ç†è®¡æ•°"""
        self.processed_count += 1
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            import psutil
            process = psutil.Process()
            current_mb = process.memory_info().rss / 1024 / 1024
            
            avg_memory = sum(self.memory_samples) / len(self.memory_samples) if self.memory_samples else 0
            
            return {
                'current_memory_mb': current_mb,
                'max_memory_mb': self.max_memory_seen,
                'avg_memory_mb': avg_memory,
                'cleanup_count': self.cleanup_count,
                'processed_count': self.processed_count,
                'uptime_hours': (time.time() - self.start_time) / 3600
            }
        except Exception:
            return {}

class DistributedTaskManager:
    """åˆ†å¸ƒå¼ä»»åŠ¡ç®¡ç†å™¨ - å¤šç”µè„‘åä½œæ ¸å¿ƒ"""
    
    def __init__(self, db_manager: 'DatabaseManager', computer_name: str):
        self.db_manager = db_manager
        self.computer_name = computer_name
        self.heartbeat_thread = None
        self.shutdown_event = threading.Event()
        self.last_heartbeat = time.time()
        
        if ENABLE_DISTRIBUTED_PROCESSING:
            self._start_heartbeat()
    
    def _start_heartbeat(self):
        """å¯åŠ¨å¿ƒè·³æœºåˆ¶"""
        def heartbeat_worker():
            while not self.shutdown_event.is_set():
                try:
                    self._send_heartbeat()
                    time.sleep(HEARTBEAT_INTERVAL)
                except Exception as e:
                    logger.error(f"å¿ƒè·³å‘é€å¤±è´¥: {e}")
                    time.sleep(60)  # é”™è¯¯æ—¶ç­‰å¾…1åˆ†é’Ÿ
        
        self.heartbeat_thread = threading.Thread(target=heartbeat_worker, daemon=True)
        self.heartbeat_thread.start()
        logger.info(f"ğŸ’“ å¯åŠ¨å¿ƒè·³æœºåˆ¶ï¼Œé—´éš”{HEARTBEAT_INTERVAL}ç§’")
    
    def _send_heartbeat(self):
        """å‘é€å¿ƒè·³"""
        if not self.db_manager.is_enabled:
            return
            
        try:
            import psutil
            
            # è·å–ç³»ç»ŸçŠ¶æ€
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            
            heartbeat_data = {
                'computer_name': self.computer_name,
                'timestamp': time.time(),
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'status': 'active'
            }
            
            # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºå‘æ•°æ®åº“å‘é€å¿ƒè·³ä¿¡æ¯
            self.last_heartbeat = time.time()
            logger.debug(f"ğŸ’“ å¿ƒè·³å‘é€: CPU {cpu_percent:.1f}%, å†…å­˜ {memory.percent:.1f}%")
            
        except Exception as e:
            logger.error(f"å¿ƒè·³æ•°æ®æ”¶é›†å¤±è´¥: {e}")
    
    def claim_video_task(self, video_path: str) -> bool:
        """å£°æ˜è§†é¢‘å¤„ç†ä»»åŠ¡ - ä½¿ç”¨Video_Editingè¡¨æ£€æŸ¥æ˜¯å¦å·²å¤„ç†"""
        if not ENABLE_DISTRIBUTED_PROCESSING or not self.db_manager.is_enabled:
            return True
        
        try:
            # ç®€åŒ–åˆ†å¸ƒå¼å¤„ç†ï¼šç›´æ¥æ£€æŸ¥Video_Editingè¡¨ä¸­æ˜¯å¦å·²è¢«å¤„ç†
            cursor = self.db_manager.connection_pool.cursor()
            
            video_name = os.path.basename(video_path)
            # æ£€æŸ¥æ˜¯å¦å·²è¢«å…¶ä»–ç”µè„‘å¤„ç†å®Œæˆ
            cursor.execute(f"""
                SELECT computer_name, updated_time FROM `{TABLE_NAME}` 
                WHERE video_name = %s AND status = 1
                ORDER BY updated_time DESC LIMIT 1
            """, (video_name,))
            
            existing_record = cursor.fetchone()
            if existing_record:
                computer_name = existing_record[0]
                updated_time = existing_record[1]
                logger.info(f"ğŸ”’ è§†é¢‘å·²è¢« {computer_name} åœ¨ {updated_time} å¤„ç†å®Œæˆ: {video_name}")
                return False
            
            logger.debug(f"ğŸ” ä»»åŠ¡å¯ä»¥å¤„ç†: {video_name}")
            return True
            
        except Exception as e:
            logger.error(f"ä»»åŠ¡å£°æ˜æ£€æŸ¥å¤±è´¥: {e}")
            return True  # å¤±è´¥æ—¶å…è®¸å¤„ç†ï¼Œé¿å…é˜»å¡
    
    def release_video_task(self, video_path: str):
        """é‡Šæ”¾è§†é¢‘å¤„ç†ä»»åŠ¡ - ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸ä½¿ç”¨é¢å¤–è¡¨"""
        if not ENABLE_DISTRIBUTED_PROCESSING or not self.db_manager.is_enabled:
            return
        
        # ç®€åŒ–ç‰ˆæœ¬ï¼šä¸éœ€è¦é¢å¤–çš„é”è¡¨ï¼Œä»»åŠ¡å®Œæˆæ—¶ä¼šå†™å…¥Video_Editingè¡¨
        logger.debug(f"ğŸ”“ ä»»åŠ¡å¤„ç†å®Œæˆ: {os.path.basename(video_path)}")
    
    def cleanup_expired_locks(self):
        """æ¸…ç†è¿‡æœŸçš„ä»»åŠ¡é” - ç®€åŒ–ç‰ˆæœ¬"""
        if not ENABLE_DISTRIBUTED_PROCESSING or not self.db_manager.is_enabled:
            return
        
        # ç®€åŒ–ç‰ˆæœ¬ï¼šä¸éœ€è¦æ¸…ç†é¢å¤–çš„é”è¡¨
        logger.debug("ğŸ§¹ åˆ†å¸ƒå¼å¤„ç†æ£€æŸ¥å®Œæˆï¼ˆåŸºäºVideo_Editingè¡¨ï¼‰")
    
    def shutdown(self):
        """å…³é—­åˆ†å¸ƒå¼ä»»åŠ¡ç®¡ç†å™¨"""
        self.shutdown_event.set()
        if self.heartbeat_thread and self.heartbeat_thread.is_alive():
            self.heartbeat_thread.join(timeout=5)
        logger.info("ğŸ›‘ åˆ†å¸ƒå¼ä»»åŠ¡ç®¡ç†å™¨å·²å…³é—­")

# ==================== ç¡¬ä»¶æ£€æµ‹å™¨ ====================
class HardwareDetector:
    """ç¡¬ä»¶æ£€æµ‹å’Œä¼˜åŒ–ç±»"""
    
    def __init__(self):
        self.cpu_count = multiprocessing.cpu_count()
        self.memory_gb = psutil.virtual_memory().total / (1024**3)
        self.is_i9 = self._detect_i9_processor()
        
    def _detect_i9_processor(self) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºi9å¤„ç†å™¨"""
        try:
            cpu_info = platform.processor().lower()
            return 'i9' in cpu_info
        except Exception:
            return False
    
    def detect_hardware_capabilities(self) -> Dict[str, Any]:
        """æ£€æµ‹ç¡¬ä»¶èƒ½åŠ›"""
        # æ£€æµ‹GPUç¼–ç å™¨
        gpu_info = self._detect_gpu_capabilities()
        
        # è®¡ç®—æœ€ä½³å¹¶è¡Œæ•°
        if self.is_i9:
            max_parallel = min(self.cpu_count - 2, 20)
        else:
            max_parallel = min(self.cpu_count // 2, 8)
        
        # å†…å­˜ä¼˜åŒ–
        if self.memory_gb >= 32:
            max_parallel = min(max_parallel, int(self.memory_gb // 1.5))
        elif self.memory_gb >= 16:
            max_parallel = min(max_parallel, 10)
        else:
            max_parallel = min(max_parallel, 6)
        
        return {
            'cpu_cores': self.cpu_count,
            'memory_gb': self.memory_gb,
            'is_i9': self.is_i9,
            'max_parallel': min(max_parallel, MAX_PARALLEL_WORKERS),
            'encoder_type': gpu_info.get('encoder_type', 'software'),
            'encoder': gpu_info.get('encoder', 'libx264'),
            'encoder_options': gpu_info.get('options', {}),
        }
    
    def _detect_gpu_capabilities(self) -> Dict[str, Any]:
        """æ£€æµ‹GPUç¼–ç èƒ½åŠ›"""
        try:
            result = subprocess.run(
                [FFMPEG_PATH, '-hide_banner', '-encoders'], 
                capture_output=True, text=True, timeout=10
            )
            
            if result.returncode != 0:
                return self._get_software_config()
            
            encoders = result.stdout.lower()
            
            # NVIDIAæ£€æµ‹
            if 'h264_nvenc' in encoders:
                return {
                    'encoder_type': 'nvidia',
                    'encoder': 'h264_nvenc',
                    'options': {'preset': 'p2', 'rc': 'vbr', 'cq': '25'}
                }
            
            # AMDæ£€æµ‹
            if 'h264_amf' in encoders:
                return {
                    'encoder_type': 'amd',
                    'encoder': 'h264_amf',
                    'options': {'quality': 'balanced', 'rc': 'vbr_peak_constrained'}
                }
            
            # Intelæ£€æµ‹
            if 'h264_qsv' in encoders:
                return {
                    'encoder_type': 'intel',
                    'encoder': 'h264_qsv',
                    'options': {'preset': 'fast', 'global_quality': '25'}
                }
            
            return self._get_software_config()
            
        except Exception as e:
            logger.warning(f"GPUæ£€æµ‹å¤±è´¥: {e}")
            return self._get_software_config()
    
    def _get_software_config(self) -> Dict[str, Any]:
        """è·å–è½¯ä»¶ç¼–ç é…ç½®"""
        preset_map = {
            'highest': 'slow',
            'high': 'medium',
            'balanced': 'fast',
            'fast': 'veryfast'
        }
        
        return {
            'encoder_type': 'software',
            'encoder': 'libx264',
            'options': {
                'preset': preset_map.get(QUALITY_MODE, 'fast'),
                'crf': '23',
                'threads': '0'
            }
        }

# ==================== æ•°æ®åº“ç®¡ç†å™¨ ====================
class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨ - å¢å¼ºè¿æ¥æ± å’Œé•¿æ—¶é—´ç¨³å®šæ€§"""
    
    def __init__(self):
        self.is_enabled = ENABLE_DATABASE
        self.connection_pool = None
        self.connection_lock = threading.RLock()
        self.reconnect_attempts = 0
        self.max_reconnect_attempts = 5
        self.last_connection_check = 0
        self.connection_check_interval = 300  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡è¿æ¥
        
        # æ ¹æ®é…ç½®è·å–ç”µè„‘ä¿¡æ¯
        if AUTO_GET_COMPUTER_INFO:
            self.computer_name = COMPUTER_NAME if COMPUTER_NAME else socket.gethostname()
            self.computer_ip = COMPUTER_IP if COMPUTER_IP else self._get_local_ip()
        else:
            self.computer_name = COMPUTER_NAME
            self.computer_ip = COMPUTER_IP
        
        # æ“ä½œå‘˜ä¿¡æ¯
        self.operator = PROCESSOR_NAME if 'PROCESSOR_NAME' in globals() else "ç»¼åˆå¤„ç†å™¨"
        
        if self.is_enabled:
            self._init_database()
    
    def _get_local_ip(self):
        """è·å–æœ¬åœ°IPåœ°å€"""
        try:
            # è¿æ¥åˆ°è¿œç¨‹åœ°å€æ¥è·å–æœ¬åœ°IP
            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
                s.connect(("8.8.8.8", 80))
                return s.getsockname()[0]
        except Exception:
            return "127.0.0.1"
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± """
        try:
            # å°è¯•å¯¼å…¥pymysql
            try:
                import pymysql
                from pymysql import pooling
            except ImportError:
                logger.warning("pymysqlæ¨¡å—æœªå®‰è£…ï¼Œç¦ç”¨æ•°æ®åº“åŠŸèƒ½")
                logger.info("è¦å¯ç”¨æ•°æ®åº“åŠŸèƒ½ï¼Œè¯·è¿è¡Œ: pip install pymysql")
                self.is_enabled = False
                return
            
            # åˆ›å»ºè¿æ¥æ± é…ç½®
            pool_config = {
                'host': DB_HOST,
                'port': DB_PORT,
                'user': DB_USER,
                'password': DB_PASSWORD,
                'database': DB_NAME,
                'charset': 'utf8mb4',
                'autocommit': True,
                'ping_interval': 300,  # 5åˆ†é’Ÿpingä¸€æ¬¡
                'max_connections': 20,
                'max_idle_time': 3600,  # 1å°æ—¶ç©ºé—²è¶…æ—¶
                'retry_on_error': True
            }
            
            # ä½¿ç”¨ç®€å•è¿æ¥ï¼ˆå› ä¸ºpymysqlå¯èƒ½æ²¡æœ‰è¿æ¥æ± ï¼‰
            self.connection_pool = self._create_robust_connection()
            self._create_tables()
            logger.info("âœ… æ•°æ®åº“è¿æ¥æ± åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œç¦ç”¨æ•°æ®åº“åŠŸèƒ½: {e}")
            self.is_enabled = False
    
    def _create_robust_connection(self):
        """åˆ›å»ºå¥å£®çš„æ•°æ®åº“è¿æ¥"""
        import pymysql
        
        for attempt in range(self.max_reconnect_attempts):
            try:
                connection = pymysql.connect(
                    host=DB_HOST,
                    port=DB_PORT,
                    user=DB_USER,
                    password=DB_PASSWORD,
                    database=DB_NAME,
                    charset='utf8mb4',
                    autocommit=True,
                    connect_timeout=30,
                    read_timeout=30,
                    write_timeout=30
                )
                
                # æµ‹è¯•è¿æ¥
                connection.ping(reconnect=True)
                self.reconnect_attempts = 0
                logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ (å°è¯• {attempt + 1})")
                return connection
                
            except Exception as e:
                self.reconnect_attempts += 1
                logger.warning(f"âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_reconnect_attempts}): {e}")
                
                if attempt < self.max_reconnect_attempts - 1:
                    wait_time = min(2 ** attempt, 30)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§30ç§’
                    time.sleep(wait_time)
        
        raise Exception(f"æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({self.max_reconnect_attempts})")
    
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥ï¼ˆå¸¦å¥åº·æ£€æŸ¥ï¼‰"""
        if not self.is_enabled:
            return None
        
        with self.connection_lock:
            current_time = time.time()
            
            # å®šæœŸæ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€
            if current_time - self.last_connection_check > self.connection_check_interval:
                try:
                    if self.connection_pool:
                        self.connection_pool.ping(reconnect=True)
                        self.last_connection_check = current_time
                        logger.debug("ğŸ’“ æ•°æ®åº“è¿æ¥å¥åº·æ£€æŸ¥é€šè¿‡")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ•°æ®åº“è¿æ¥æ£€æŸ¥å¤±è´¥ï¼Œå°è¯•é‡è¿: {e}")
                    self.connection_pool = self._create_robust_connection()
                    self.last_connection_check = current_time
            
            return self.connection_pool
    
    def execute_with_retry(self, query: str, params: tuple = None, max_retries: int = 3):
        """æ‰§è¡ŒSQLè¯­å¥ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        if not self.is_enabled:
            return None
        
        for attempt in range(max_retries):
            try:
                connection = self.get_connection()
                if not connection:
                    return None
                
                with connection.cursor() as cursor:
                    cursor.execute(query, params)
                    if query.strip().upper().startswith('SELECT'):
                        return cursor.fetchall()
                    else:
                        return cursor.rowcount
                        
            except Exception as e:
                logger.warning(f"âš ï¸ SQLæ‰§è¡Œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                
                # è¿æ¥é”™è¯¯æ—¶é‡æ–°åˆ›å»ºè¿æ¥
                if "connection" in str(e).lower() or "lost" in str(e).lower():
                    try:
                        self.connection_pool = self._create_robust_connection()
                    except Exception as conn_e:
                        logger.error(f"âŒ é‡æ–°è¿æ¥å¤±è´¥: {conn_e}")
                
                if attempt == max_retries - 1:
                    logger.error(f"âŒ SQLæ‰§è¡Œæœ€ç»ˆå¤±è´¥: {query[:100]}...")
                    raise e
                
                time.sleep(1 * (attempt + 1))  # é€’å¢ç­‰å¾…æ—¶é—´
        
        return None
    
    def _create_tables(self):
        """åˆ›å»ºæ•°æ®åº“è¡¨ - ä¸¥æ ¼ä½¿ç”¨11ä¸ªå›ºå®šå­—æ®µ"""
        if not self.is_enabled:
            return
            
        try:
            cursor = self.connection_pool.cursor()
            
            # ã€å›ºå®šã€‘åˆ›å»ºVideo_Editingè¡¨ï¼Œä¸¥æ ¼ä½¿ç”¨11ä¸ªå­—æ®µï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–å­—æ®µ
            create_table_query = f"""
            CREATE TABLE IF NOT EXISTS `{TABLE_NAME}` (
                `input_path` VARCHAR(1024) NOT NULL COMMENT 'è¾“å…¥è·¯å¾„',
                `output_path` VARCHAR(1024) COMMENT 'è¾“å‡ºè·¯å¾„',
                `video_name` VARCHAR(255) NOT NULL COMMENT 'è§†é¢‘å',
                `pre_processing_size` BIGINT COMMENT 'å¤„ç†å‰è§†é¢‘å¤§å° (Bytes)',
                `resolution` VARCHAR(50) COMMENT 'åˆ†è¾¨ç‡',
                `hash_value` VARCHAR(64) NOT NULL COMMENT 'å“ˆå¸Œå€¼',
                `operator` VARCHAR(100) COMMENT 'å¤„ç†äºº',
                `computer_name` VARCHAR(100) COMMENT 'ç”µè„‘å·',
                `computer_ip` VARCHAR(50) COMMENT 'ç”µè„‘IP',
                `status` TINYINT NOT NULL COMMENT 'å¤„ç†çŠ¶æ€ 0: å¤±è´¥, 1: æˆåŠŸ',
                `log_path` VARCHAR(1024) COMMENT 'æ—¥å¿—è·¯å¾„',
                `created_time` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
                `updated_time` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                UNIQUE KEY `hash_value_unique` (`hash_value`)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
            """
            cursor.execute(create_table_query)
            
            self.connection_pool.commit()
            logger.info("âœ… Video_Editingè¡¨åˆ›å»ºæˆåŠŸ (11ä¸ªå›ºå®šå­—æ®µ)")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ•°æ®åº“è¡¨å¤±è´¥: {e}")
    
    def is_video_processed(self, video_path: str, file_hash: str) -> Tuple[bool, Optional[Dict]]:
        """æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²å¤„ç† - ä½¿ç”¨11ä¸ªå›ºå®šå­—æ®µ"""
        if not self.is_enabled:
            return False, None
            
        try:
            cursor = self.connection_pool.cursor()
            cursor.execute(f"""
                SELECT input_path, output_path, computer_name, created_time 
                FROM `{TABLE_NAME}` 
                WHERE hash_value = %s AND status = 1
                ORDER BY created_time DESC LIMIT 1
            """, (file_hash,))
            
            result = cursor.fetchone()
            if result:
                return True, {
                    'input_path': result[0],
                    'output_path': result[1],
                    'computer_name': result[2],
                    'created_time': result[3]
                }
            return False, None
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")
            return False, None
    
    def enhanced_duplicate_check(self, video_path: str) -> Tuple[bool, str]:
        """å¢å¼ºçš„æŸ¥é‡æ£€æŸ¥ - ä½¿ç”¨11ä¸ªå›ºå®šå­—æ®µ"""
        if not self.is_enabled:
            return False, "æ•°æ®åº“æœªå¯ç”¨"
            
        try:
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = self._calculate_video_sha256(video_path)
            if not file_hash:
                return False, "æ— æ³•è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"
            
            video_name = os.path.basename(video_path)
            
            cursor = self.connection_pool.cursor()
            # ä½¿ç”¨hash_valueå’Œvideo_nameåŒé‡éªŒè¯ï¼ˆåªæŸ¥è¯¢11ä¸ªå›ºå®šå­—æ®µï¼‰
            cursor.execute(f"""
                SELECT computer_name, updated_time, output_path
                FROM `{TABLE_NAME}`
                WHERE hash_value = %s AND video_name = %s AND status = 1
                ORDER BY updated_time DESC LIMIT 1
            """, (file_hash, video_name))
            
            result = cursor.fetchone()
            if result:
                computer_name = result[0]
                updated_time = result[1]
                output_path = result[2]
                return True, f"å·²è¢« {computer_name} åœ¨ {updated_time} å¤„ç†è¿‡ï¼Œè¾“å‡º: {output_path}"
            else:
                return False, "æœªå‘ç°é‡å¤"
                
        except Exception as e:
            logger.error(f"æŸ¥é‡æ£€æŸ¥å¤±è´¥: {e}")
            return False, f"æŸ¥é‡æ£€æŸ¥å¼‚å¸¸: {e}"
    
    def _calculate_video_sha256(self, video_path: str, quick_mode: bool = False) -> str:
        """è®¡ç®—è§†é¢‘æ–‡ä»¶SHA256 - å‚è€ƒMC_Lè„šæœ¬"""
        try:
            if not os.path.exists(video_path):
                return ""
                
            import hashlib
            hash_sha256 = hashlib.sha256()
            
            if quick_mode:
                # å¿«é€Ÿæ¨¡å¼ï¼šé‡‡æ ·æ–‡ä»¶å¤´ã€ä¸­é—´ã€å°¾éƒ¨
                file_size = os.path.getsize(video_path)
                sample_size = min(1024 * 1024, file_size // 10)  # 1MBæˆ–æ–‡ä»¶çš„1/10
                
                with open(video_path, 'rb') as f:
                    # æ–‡ä»¶å¤´
                    hash_sha256.update(f.read(sample_size))
                    
                    # æ–‡ä»¶ä¸­é—´
                    if file_size > sample_size * 2:
                        f.seek(file_size // 2)
                        hash_sha256.update(f.read(sample_size))
                    
                    # æ–‡ä»¶å°¾
                    if file_size > sample_size * 3:
                        f.seek(-sample_size, 2)
                        hash_sha256.update(f.read(sample_size))
            else:
                # å®Œæ•´æ¨¡å¼ï¼šè®¡ç®—æ•´ä¸ªæ–‡ä»¶
                with open(video_path, 'rb') as f:
                    while chunk := f.read(8192):
                        hash_sha256.update(chunk)
            
            return hash_sha256.hexdigest()
            
        except Exception as e:
            logger.error(f"è®¡ç®—SHA256å¤±è´¥ {video_path}: {e}")
            return ""
    
    
    def record_processing_complete(self, video_path: str, output_path: str, 
                                  processing_time: float = 0.0, log_path: str = None) -> bool:
        """è®°å½•è§†é¢‘å¤„ç†å®Œæˆ - ä¸¥æ ¼å†™å…¥11ä¸ªå›ºå®šå­—æ®µ"""
        if not self.is_enabled:
            return True
            
        try:
            # è·å–çœŸå®çš„è§†é¢‘ä¿¡æ¯
            video_name = os.path.basename(video_path)
            pre_processing_size = os.path.getsize(video_path) if os.path.exists(video_path) else 0
            
            # è®¡ç®—çœŸå®çš„å“ˆå¸Œå€¼
            hash_value = self._calculate_video_sha256(video_path, quick_mode=False)
            if not hash_value:
                logger.warning(f"æ— æ³•è®¡ç®—å“ˆå¸Œå€¼: {video_name}")
                return False
                
            # è·å–çœŸå®çš„è§†é¢‘åˆ†è¾¨ç‡
            resolution = None
            try:
                video_info = self._get_real_video_info(video_path)
                if video_info and video_info.get('width') and video_info.get('height'):
                    resolution = f"{video_info['width']}x{video_info['height']}"
            except Exception as e:
                logger.warning(f"è·å–è§†é¢‘åˆ†è¾¨ç‡å¤±è´¥: {e}")
            
            cursor = self.connection_pool.cursor()
            
            # ã€å›ºå®šã€‘ä¸¥æ ¼æ’å…¥11ä¸ªå­—æ®µï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–å­—æ®µ
            insert_sql = f"""
            INSERT INTO `{TABLE_NAME}` 
            (input_path, output_path, video_name, pre_processing_size, resolution, 
             hash_value, operator, computer_name, computer_ip, status, log_path)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, 1, %s)
            ON DUPLICATE KEY UPDATE
            output_path = VALUES(output_path),
            status = 1,
            updated_time = CURRENT_TIMESTAMP
            """
            
            cursor.execute(insert_sql, (
                video_path,                # input_path
                output_path,               # output_path  
                video_name,                # video_name
                pre_processing_size,       # pre_processing_size
                resolution,                # resolution
                hash_value,                # hash_value
                OPERATOR_NAME,             # operator (ä½¿ç”¨é…ç½®çš„æ“ä½œå‘˜åç§°)
                self.computer_name,        # computer_name
                self.computer_ip,          # computer_ip
                log_path                   # log_path
            ))
            
            self.connection_pool.commit()
            logger.info(f"âœ… æ•°æ®åº“è®°å½•å®Œæˆ (11ä¸ªå›ºå®šå­—æ®µ): {video_name}")
            logger.debug(f"   å“ˆå¸Œå€¼: {hash_value}")
            logger.debug(f"   åˆ†è¾¨ç‡: {resolution}")
            logger.debug(f"   æ–‡ä»¶å¤§å°: {pre_processing_size} bytes")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è®°å½•å¤±è´¥: {e}")
            return False
    
    def _get_real_video_info(self, video_path: str) -> Dict[str, Any]:
        """è·å–çœŸå®çš„è§†é¢‘ä¿¡æ¯"""
        try:
            # ä½¿ç”¨ffprobeè·å–å‡†ç¡®çš„è§†é¢‘ä¿¡æ¯
            cmd = [
                'ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_streams',
                '-select_streams', 'v:0', video_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, 
                                  encoding='utf-8', errors='ignore')
            
            if result.returncode == 0:
                import json
                data = json.loads(result.stdout)
                streams = data.get('streams', [])
                
                if streams:
                    video_stream = streams[0]
                    return {
                        'width': video_stream.get('width', 0),
                        'height': video_stream.get('height', 0),
                        'duration': float(video_stream.get('duration', 0)),
                        'bit_rate': video_stream.get('bit_rate', ''),
                        'codec_name': video_stream.get('codec_name', '')
                    }
            
            return {}
            
        except Exception as e:
            logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            return {}

# ==================== æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨ ====================
class SmartCacheManager:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨ - å¢å¼ºç¼“å­˜åæŸ¥é‡åŠŸèƒ½"""
    
    def __init__(self, db_manager: DatabaseManager = None):
        self.cache_dir = Path(CACHE_DIR)
        self.cache_dir.mkdir(exist_ok=True)
        self.max_cache_size = MAX_CACHE_SIZE_GB * 1024**3  # è½¬æ¢ä¸ºå­—èŠ‚
        self.cache_records = {}
        self.download_queue = queue.Queue()
        self.download_threads = []
        self.is_enabled = ENABLE_CACHE
        self.db_manager = db_manager  # ç”¨äºç¼“å­˜åæŸ¥é‡
        
        # ç¼“å­˜å®Œæˆè®°å½•
        self.cache_completion_file = self.cache_dir / ".cache_completion.json"
        self.completed_cache_videos = set()
        
        if self.is_enabled:
            self._start_cache_threads()
            self._load_cache_records()
            self._load_cache_completion_record()
    
    def _start_cache_threads(self):
        """å¯åŠ¨ç¼“å­˜çº¿ç¨‹"""
        # ä¸‹è½½çº¿ç¨‹
        for i in range(2):
            thread = threading.Thread(target=self._download_worker, daemon=True)
            thread.start()
            self.download_threads.append(thread)
        
        # æ¸…ç†çº¿ç¨‹
        cleanup_thread = threading.Thread(target=self._cleanup_monitor, daemon=True)
        cleanup_thread.start()
    
    def _load_cache_records(self):
        """åŠ è½½ç¼“å­˜è®°å½•"""
        cache_record_file = self.cache_dir / "cache_records.json"
        if cache_record_file.exists():
            try:
                with open(cache_record_file, 'r', encoding='utf-8') as f:
                    self.cache_records = json.load(f)
                logger.info(f"åŠ è½½ç¼“å­˜è®°å½•: {len(self.cache_records)} ä¸ªæ–‡ä»¶")
            except Exception as e:
                logger.warning(f"åŠ è½½ç¼“å­˜è®°å½•å¤±è´¥: {e}")
                self.cache_records = {}
    
    def _save_cache_records(self):
        """ä¿å­˜ç¼“å­˜è®°å½•"""
        cache_record_file = self.cache_dir / "cache_records.json"
        try:
            with open(cache_record_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache_records, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.warning(f"ä¿å­˜ç¼“å­˜è®°å½•å¤±è´¥: {e}")
    
    def _load_cache_completion_record(self):
        """åŠ è½½ç¼“å­˜å®Œæˆè®°å½•"""
        try:
            if self.cache_completion_file.exists():
                with open(self.cache_completion_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.completed_cache_videos = set(data.get('completed_videos', []))
                    logger.debug(f"ğŸ“‹ åŠ è½½ç¼“å­˜å®Œæˆè®°å½•: {len(self.completed_cache_videos)}ä¸ªè§†é¢‘")
            else:
                self.completed_cache_videos = set()
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½ç¼“å­˜å®Œæˆè®°å½•å¤±è´¥: {e}")
            self.completed_cache_videos = set()
    
    def _save_cache_completion_record(self):
        """ä¿å­˜ç¼“å­˜å®Œæˆè®°å½•"""
        try:
            with open(self.cache_completion_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'completed_videos': list(self.completed_cache_videos),
                    'last_updated': time.time()
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ğŸ’¾ ä¿å­˜ç¼“å­˜å®Œæˆè®°å½•å¤±è´¥: {e}")
    
    def mark_cache_completed(self, video_path: str):
        """æ ‡è®°è§†é¢‘ç¼“å­˜å®Œæˆ"""
        self.completed_cache_videos.add(video_path)
        self._save_cache_completion_record()
        logger.debug(f"âœ… æ ‡è®°ç¼“å­˜å®Œæˆ: {os.path.basename(video_path)}")
    
    def is_cache_completed(self, video_path: str) -> bool:
        """æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²å®Œæˆç¼“å­˜"""
        return video_path in self.completed_cache_videos
    
    def get_cached_path(self, video_path: str) -> Optional[str]:
        """è·å–ç¼“å­˜è·¯å¾„"""
        if not self.is_enabled:
            return None
        
        video_name = os.path.basename(video_path)
        cache_path = self.cache_dir / video_name
        
        if cache_path.exists() and self._verify_cache_integrity(str(cache_path), video_path):
            # æ›´æ–°è®¿é—®æ—¶é—´
            self.cache_records[video_path] = {
                'cache_path': str(cache_path),
                'last_access': time.time(),
                'file_size': cache_path.stat().st_size
            }
            self._save_cache_records()
            return str(cache_path)
        
        return None
    
    def _verify_cache_integrity(self, cache_path: str, original_path: str) -> bool:
        """éªŒè¯ç¼“å­˜å®Œæ•´æ€§"""
        try:
            if not os.path.exists(cache_path):
                return False
            
            # æ¯”è¾ƒæ–‡ä»¶å¤§å°
            cache_size = os.path.getsize(cache_path)
            if os.path.exists(original_path):
                original_size = os.path.getsize(original_path)
                if abs(cache_size - original_size) > 1024:  # å…è®¸1KBå·®å¼‚
                    return False
            
            # éªŒè¯è§†é¢‘å¯è¯»æ€§
            probe_cmd = [FFPROBE_PATH, '-v', 'error', '-show_entries', 'format=duration', 
                        '-of', 'default=noprint_wrappers=1:nokey=1', cache_path]
            result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=10, encoding='utf-8', errors='ignore')
            
            return result.returncode == 0 and result.stdout.strip()
            
        except Exception as e:
            logger.warning(f"ç¼“å­˜å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}")
            return False
    
    def start_async_download(self, video_path: str, priority: int = 0) -> bool:
        """å¼€å§‹å¼‚æ­¥ä¸‹è½½"""
        if not self.is_enabled:
            return False
        
        if self.get_cached_path(video_path):
            return True  # å·²ç¼“å­˜
        
        try:
            self.download_queue.put((priority, video_path))
            return True
        except Exception as e:
            logger.error(f"æ·»åŠ ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
            return False
    
    def _download_worker(self):
        """ä¸‹è½½å·¥ä½œçº¿ç¨‹"""
        while True:
            try:
                priority, video_path = self.download_queue.get(timeout=1)
                self._download_video_to_cache(video_path)
                self.download_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"ä¸‹è½½å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
    
    def _download_video_to_cache(self, video_path: str) -> bool:
        """ä¸‹è½½è§†é¢‘åˆ°ç¼“å­˜ - å¢å¼ºç¼“å­˜åæŸ¥é‡åŠŸèƒ½"""
        try:
            if not os.path.exists(video_path):
                logger.error(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return False
            
            video_name = os.path.basename(video_path)
            cache_path = self.cache_dir / video_name
            
            # æ£€æŸ¥ç¼“å­˜ç©ºé—´
            if not self._ensure_cache_space(os.path.getsize(video_path)):
                logger.warning(f"ç¼“å­˜ç©ºé—´ä¸è¶³ï¼Œè·³è¿‡: {video_name}")
                return False
            
            # å¤åˆ¶æ–‡ä»¶
            logger.info(f"ğŸš€ å¼€å§‹ç¼“å­˜: {video_name}")
            start_time = time.time()
            
            shutil.copy2(video_path, cache_path)
            
            download_time = time.time() - start_time
            
            # è®°å½•ç¼“å­˜ä¿¡æ¯
            self.cache_records[video_path] = {
                'cache_path': str(cache_path),
                'last_access': time.time(),
                'download_time': download_time,
                'file_size': cache_path.stat().st_size
            }
            self._save_cache_records()
            
            # ğŸ¯ å…³é”®åŠŸèƒ½ï¼šç¼“å­˜å®Œæˆåç«‹å³æ‰§è¡ŒæŸ¥é‡æ£€æŸ¥
            self.mark_cache_completed(video_path)
            
            # æ‰§è¡Œç¼“å­˜åæŸ¥é‡ï¼ˆå‚è€ƒMC_Lè„šæœ¬é€»è¾‘ï¼‰
            if self.db_manager and self.db_manager.is_enabled:
                try:
                    is_duplicate, message = self.db_manager.enhanced_duplicate_check(video_path)
                    if is_duplicate:
                        logger.info(f"ğŸ” ç¼“å­˜åå‘ç°é‡å¤: {video_name} - {message}")
                        
                        # æ¸…ç†ç¼“å­˜æ–‡ä»¶ï¼ˆèŠ‚çœç£ç›˜ç©ºé—´ï¼‰
                        try:
                            if cache_path.exists():
                                cache_path.unlink()
                                logger.debug(f"ğŸ—‘ï¸ æ¸…ç†é‡å¤æ–‡ä»¶ç¼“å­˜: {video_name}")
                                
                                # ä»ç¼“å­˜è®°å½•ä¸­ç§»é™¤
                                if video_path in self.cache_records:
                                    del self.cache_records[video_path]
                                    self._save_cache_records()
                        except Exception as e:
                            logger.warning(f"æ¸…ç†é‡å¤ç¼“å­˜å¤±è´¥: {e}")
                        
                        return False  # è¿”å›Falseè¡¨ç¤ºåº”è·³è¿‡å¤„ç†
                    else:
                        logger.debug(f"ğŸ“ ç¼“å­˜åæŸ¥é‡æ£€æŸ¥é€šè¿‡: {video_name} - {message}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ ç¼“å­˜åæŸ¥é‡æ£€æŸ¥å¤±è´¥: {e}")
                    # æŸ¥é‡å¤±è´¥ä¸å½±å“ç¼“å­˜ï¼Œç»§ç»­å¤„ç†
            
            logger.info(f"ç¼“å­˜å®Œæˆ: {video_name} ({download_time:.1f}s)")
            return True
            
        except Exception as e:
            logger.error(f"ç¼“å­˜å¤±è´¥ {video_path}: {e}")
            return False
    
    def _ensure_cache_space(self, required_space: int) -> bool:
        """ç¡®ä¿ç¼“å­˜ç©ºé—´å……è¶³"""
        current_size = self._get_cache_size()
        
        while current_size + required_space > self.max_cache_size:
            if not self._cleanup_oldest_cache():
                return False
            current_size = self._get_cache_size()
        
        return True
    
    def _get_cache_size(self) -> int:
        """è·å–å½“å‰ç¼“å­˜å¤§å°"""
        total_size = 0
        try:
            for cache_file in self.cache_dir.iterdir():
                if cache_file.is_file():
                    total_size += cache_file.stat().st_size
        except Exception as e:
            logger.warning(f"è®¡ç®—ç¼“å­˜å¤§å°å¤±è´¥: {e}")
        return total_size
    
    def _cleanup_oldest_cache(self) -> bool:
        """æ¸…ç†æœ€æ—§çš„ç¼“å­˜"""
        if not self.cache_records:
            return False
        
        # æŒ‰æœ€åè®¿é—®æ—¶é—´æ’åº
        sorted_records = sorted(
            self.cache_records.items(),
            key=lambda x: x[1].get('last_access', 0)
        )
        
        for video_path, record in sorted_records:
            cache_path = record['cache_path']
            try:
                if os.path.exists(cache_path):
                    os.remove(cache_path)
                    logger.info(f"æ¸…ç†ç¼“å­˜: {os.path.basename(cache_path)}")
                
                del self.cache_records[video_path]
                self._save_cache_records()
                return True
                
            except Exception as e:
                logger.warning(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        
        return False
    
    def _cleanup_monitor(self):
        """ç¼“å­˜æ¸…ç†ç›‘æ§çº¿ç¨‹"""
        while True:
            try:
                time.sleep(300)  # æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
                current_size = self._get_cache_size()
                if current_size > self.max_cache_size * CACHE_CLEANUP_THRESHOLD:
                    logger.info("å¼€å§‹è‡ªåŠ¨æ¸…ç†ç¼“å­˜...")
                    self._cleanup_old_cache()
                
            except Exception as e:
                logger.error(f"ç¼“å­˜æ¸…ç†ç›‘æ§å¼‚å¸¸: {e}")
    
    def _cleanup_old_cache(self):
        """æ¸…ç†æ—§ç¼“å­˜"""
        # æ¸…ç†è¶…è¿‡7å¤©æœªè®¿é—®çš„ç¼“å­˜
        cutoff_time = time.time() - 7 * 24 * 3600
        
        to_remove = []
        for video_path, record in self.cache_records.items():
            if record.get('last_access', 0) < cutoff_time:
                to_remove.append(video_path)
        
        for video_path in to_remove:
            record = self.cache_records[video_path]
            cache_path = record['cache_path']
            try:
                if os.path.exists(cache_path):
                    os.remove(cache_path)
                del self.cache_records[video_path]
            except Exception as e:
                logger.warning(f"æ¸…ç†æ—§ç¼“å­˜å¤±è´¥: {e}")
        
        if to_remove:
            self._save_cache_records()
            logger.info(f"æ¸…ç†äº† {len(to_remove)} ä¸ªæ—§ç¼“å­˜æ–‡ä»¶")
    
    def wait_for_cache(self, video_path: str, timeout: float = 300) -> Optional[str]:
        """ç­‰å¾…ç¼“å­˜å®Œæˆ"""
        if not self.is_enabled:
            return None
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            cached_path = self.get_cached_path(video_path)
            if cached_path:
                return cached_path
            time.sleep(1)
        
        return None
    
    def preload_videos(self, video_paths: List[str], current_index: int):
        """é¢„åŠ è½½è§†é¢‘"""
        if not self.is_enabled or PRELOAD_COUNT <= 0:
            return
        
        # é¢„åŠ è½½æ¥ä¸‹æ¥çš„å‡ ä¸ªè§†é¢‘
        for i in range(1, PRELOAD_COUNT + 1):
            next_index = current_index + i
            if next_index < len(video_paths):
                self.start_async_download(video_paths[next_index], priority=-i)

# ==================== ROIé€‰æ‹©å™¨ ====================
class ROISelector:
    """ROIåŒºåŸŸé€‰æ‹©å™¨"""
    
    def __init__(self):
        self.gui_available = self._init_opencv_gui()
    
    def _init_opencv_gui(self) -> bool:
        """åˆå§‹åŒ–OpenCV GUI"""
        try:
            # æ£€æŸ¥OpenCVç‰ˆæœ¬
            current_version = cv2.__version__
            logger.info(f"OpenCVç‰ˆæœ¬: {current_version}")
            
            # æµ‹è¯•GUIåŠŸèƒ½
            test_img = np.zeros((100, 100, 3), dtype=np.uint8)
            cv2.namedWindow("test_window", cv2.WINDOW_NORMAL)
            cv2.imshow("test_window", test_img)
            cv2.waitKey(1)
            cv2.destroyWindow("test_window")
            
            logger.info("OpenCV GUIåˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.warning(f"OpenCV GUIåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def extract_preview_frame(self, video_path: str) -> Optional[np.ndarray]:
        """æå–é¢„è§ˆå¸§"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            probe_cmd = [FFPROBE_PATH, '-v', 'error', '-show_entries', 'format=duration',
                        '-of', 'default=noprint_wrappers=1:nokey=1', video_path]
            result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=10, encoding='utf-8', errors='ignore')
            
            if result.returncode != 0:
                return None
            
            duration = float(result.stdout.strip())
            seek_time = duration / 2  # ä»ä¸­é—´æå–å¸§
            
            # æå–å¸§
            temp_frame_path = Path("temp_preview_frame.jpg")
            extract_cmd = [
                FFMPEG_PATH, '-ss', str(seek_time), '-i', video_path,
                '-vframes', '1', '-q:v', '2', str(temp_frame_path), '-y'
            ]
            
            result = subprocess.run(extract_cmd, capture_output=True, timeout=30, encoding='utf-8', errors='ignore')
            
            if result.returncode == 0 and temp_frame_path.exists():
                frame = cv2.imread(str(temp_frame_path))
                temp_frame_path.unlink()  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                return frame
            
            return None
            
        except Exception as e:
            logger.error(f"æå–é¢„è§ˆå¸§å¤±è´¥: {e}")
            return None
    
    def select_roi_for_video(self, video_path: str) -> Optional[Tuple[int, int, int, int, int, int]]:
        """ä¸ºè§†é¢‘é€‰æ‹©ROIåŒºåŸŸï¼Œè¿”å› (x, y, w, h, base_width, base_height)"""
        frame = self.extract_preview_frame(video_path)
        if frame is None:
            logger.error(f"æ— æ³•æå–é¢„è§ˆå¸§: {video_path}")
            return None
        
        height, width = frame.shape[:2]
        print(f"ğŸ“ åŸºå‡†è§†é¢‘å°ºå¯¸: {width}x{height}")
        print("ğŸ’¡ æç¤º: åœ¨æ­¤åˆ†è¾¨ç‡ä¸‹é€‰æ‹©çš„è£å‰ªæ¡†å°†è‡ªåŠ¨é€‚é…2K/4Kç­‰ä¸åŒåˆ†è¾¨ç‡è§†é¢‘")
        
        if self.gui_available:
            roi = self._gui_select_roi(frame)
        else:
            roi = self._fallback_roi_input(frame)
        
        if roi is None:
            return None
        
        # è¿”å›ROI + åŸºå‡†åˆ†è¾¨ç‡ï¼Œç”¨äºåç»­æ¯”ä¾‹ç¼©æ”¾
        return roi + (width, height)
    
    def _gui_select_roi(self, frame: np.ndarray) -> Optional[Tuple[int, int, int, int]]:
        """GUIæ–¹å¼é€‰æ‹©ROI"""
        try:
            # è°ƒæ•´æ˜¾ç¤ºå°ºå¯¸ - ä½¿ç”¨æ›´å¤§çš„çª—å£
            height, width = frame.shape[:2]
            
            # è®¾ç½®ç›®æ ‡æ˜¾ç¤ºé«˜åº¦ä¸º1200åƒç´ ï¼ˆæ›´å¤§çš„çª—å£ï¼‰
            target_height = 1200
            if height > target_height:
                scale = target_height / height
                new_width = int(width * scale)
                display_frame = cv2.resize(frame, (new_width, target_height))
            elif height < 600:  # å¦‚æœåŸå§‹å›¾åƒå¤ªå°ï¼Œæ”¾å¤§æ˜¾ç¤º
                scale = 600 / height
                new_width = int(width * scale)
                display_frame = cv2.resize(frame, (new_width, 600))
            else:
                display_frame = frame.copy()
                scale = 1.0
            
            # æ·»åŠ æç¤ºæ–‡å­—å’Œåˆ†è¾¨ç‡ä¿¡æ¯
            info_text = f"Video: {width}x{height} (Base Resolution for Scaling)"
            cv2.putText(display_frame, info_text, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            cv2.putText(display_frame, "Select ROI area, then press SPACE or ENTER", 
                       (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            cv2.putText(display_frame, "This selection will auto-scale for 2K/4K videos", 
                       (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # é€‰æ‹©ROI - è®¾ç½®çª—å£ä¸ºå¯è°ƒæ•´å¤§å°
            window_name = "Select ROI Area (Drag to select, SPACE/ENTER to confirm, ESC to cancel)"
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)
            
            # è®¾ç½®çª—å£åˆå§‹å¤§å°ï¼ˆæ›´å¤§ï¼‰
            cv2.resizeWindow(window_name, display_frame.shape[1], display_frame.shape[0])
            
            # æ˜¾ç¤ºå›¾åƒå¹¶ç­‰å¾…ç”¨æˆ·é€‰æ‹©
            cv2.imshow(window_name, display_frame)
            cv2.waitKey(100)  # ç­‰å¾…çª—å£å®Œå…¨æ˜¾ç¤º
            
            roi = cv2.selectROI(window_name, display_frame, fromCenter=False, showCrosshair=True)
            cv2.destroyAllWindows()
            
            if roi[2] == 0 or roi[3] == 0:
                logger.warning("æœªé€‰æ‹©æœ‰æ•ˆROIåŒºåŸŸ")
                return None
            
            # è½¬æ¢ä¸ºåŸå§‹å°ºå¯¸åæ ‡
            x = int(roi[0] / scale)
            y = int(roi[1] / scale)
            w = int(roi[2] / scale)
            h = int(roi[3] / scale)
            
            # ç”¨æˆ·é€‰æ‹©çš„åŸå§‹ROI
            original_roi = (x, y, w, h)
            print(f'æ‚¨é€‰æ‹©çš„è£å‰ªæ¡† (åŸå§‹å°ºå¯¸): {original_roi}')
            
            # è°ƒæ•´ä¸º16:9æ¯”ä¾‹
            final_roi = self._adjust_roi_to_16_9((x, y, w, h), width, height)
            print(f'è„šæœ¬è®¡ç®—å‡ºçš„æœ€ç»ˆ16:9è£å‰ªå‚æ•°: {final_roi}')
            
            # æ˜¾ç¤ºæœ€ç»ˆè£å‰ªæ¡†é¢„è§ˆ
            self._show_roi_preview(frame, original_roi, final_roi, scale)
            
            return final_roi
            
        except Exception as e:
            logger.error(f"GUIé€‰æ‹©ROIå¤±è´¥: {e}")
            return None
    
    def _fallback_roi_input(self, frame: np.ndarray) -> Optional[Tuple[int, int, int, int]]:
        """å¤‡ç”¨å‘½ä»¤è¡Œè¾“å…¥ROI"""
        height, width = frame.shape[:2]
        
        print(f"ğŸ“ è§†é¢‘å°ºå¯¸: {width}x{height} (åŸºå‡†åˆ†è¾¨ç‡)")
        print("ğŸ’¡ æç¤º: é€‰æ‹©çš„è£å‰ªæ¡†å°†è‡ªåŠ¨é€‚é…2K/4Kç­‰ä¸åŒåˆ†è¾¨ç‡è§†é¢‘")
        print("è¯·è¾“å…¥ROIåæ ‡ (x y w h)ï¼Œä»¥ç©ºæ ¼åˆ†éš”:")
        
        while True:
            try:
                user_input = input().strip()
                coords = list(map(int, user_input.split()))
                
                if len(coords) != 4:
                    print("è¯·è¾“å…¥4ä¸ªæ•°å­—: x y w h")
                    continue
                
                x, y, w, h = coords
                
                # éªŒè¯åæ ‡æœ‰æ•ˆæ€§
                if (x >= 0 and y >= 0 and w > 0 and h > 0 and 
                    x + w <= width and y + h <= height):
                    
                    original_roi = (x, y, w, h)
                    print(f'æ‚¨è¾“å…¥çš„è£å‰ªæ¡† (åŸå§‹å°ºå¯¸): {original_roi}')
                    
                    # è°ƒæ•´ä¸º16:9æ¯”ä¾‹
                    final_roi = self._adjust_roi_to_16_9((x, y, w, h), width, height)
                    print(f'è„šæœ¬è®¡ç®—å‡ºçš„æœ€ç»ˆ16:9è£å‰ªå‚æ•°: {final_roi}')
                    
                    # æ˜¾ç¤ºé¢„è§ˆï¼ˆå¦‚æœå¯èƒ½çš„è¯ï¼‰
                    try:
                        scale = 800 / height if height > 0 else 1
                        self._show_roi_preview(frame, original_roi, final_roi, scale)
                    except Exception as e:
                        print(f"âš ï¸ æ— æ³•æ˜¾ç¤ºé¢„è§ˆ: {e}")
                    
                    return final_roi
                else:
                    print("åæ ‡è¶…å‡ºè§†é¢‘èŒƒå›´ï¼Œè¯·é‡æ–°è¾“å…¥")
                    
            except ValueError:
                print("è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥4ä¸ªæ•´æ•°")
            except KeyboardInterrupt:
                return None
    
    def _adjust_roi_to_16_9(self, roi: Tuple[int, int, int, int], 
                           video_width: int, video_height: int) -> Tuple[int, int, int, int]:
        """è°ƒæ•´ROIä¸º16:9æ¯”ä¾‹"""
        x, y, w, h = roi
        target_aspect = 16 / 9
        current_aspect = w / h if h > 0 else target_aspect
        
        # åœ¨é€‰æ‹©åŒºåŸŸå†…æ‰¾åˆ°æœ€å¤§çš„16:9çŸ©å½¢
        if current_aspect > target_aspect:
            # å½“å‰åŒºåŸŸæ›´å®½ï¼Œä»¥é«˜åº¦ä¸ºå‡†
            new_h = h
            new_w = int(h * target_aspect)
            new_x = x + (w - new_w) // 2
            new_y = y
        else:
            # å½“å‰åŒºåŸŸæ›´é«˜ï¼Œä»¥å®½åº¦ä¸ºå‡†
            new_w = w
            new_h = int(w / target_aspect)
            new_x = x
            new_y = y + (h - new_h) // 2
        
        # ç¡®ä¿ä¸è¶…å‡ºè§†é¢‘è¾¹ç•Œ
        new_x = max(0, min(new_x, video_width - new_w))
        new_y = max(0, min(new_y, video_height - new_h))
        
        if new_x + new_w > video_width:
            new_w = video_width - new_x
            new_h = int(new_w / target_aspect)
        
        if new_y + new_h > video_height:
            new_h = video_height - new_y
            new_w = int(new_h * target_aspect)
        
        logger.info(f"ROIè°ƒæ•´: {roi} -> ({new_x}, {new_y}, {new_w}, {new_h})")
        return (new_x, new_y, new_w, new_h)
    
    def _show_roi_preview(self, frame: np.ndarray, original_roi: Tuple[int, int, int, int], 
                         final_roi: Tuple[int, int, int, int], scale: float):
        """æ˜¾ç¤ºROIé¢„è§ˆå¯¹æ¯”
        
        Args:
            frame: åŸå§‹è§†é¢‘å¸§
            original_roi: ç”¨æˆ·é€‰æ‹©çš„åŸå§‹ROI (x, y, w, h)
            final_roi: è°ƒæ•´åçš„16:9 ROI (x, y, w, h)
            scale: æ˜¾ç¤ºç¼©æ”¾æ¯”ä¾‹
        """
        try:
            # åˆ›å»ºé¢„è§ˆå›¾åƒ
            preview_image = frame.copy()
            
            # ç”»å‡ºç”¨æˆ·é€‰æ‹©çš„æ¡† (çº¢è‰²)
            cv2.rectangle(preview_image, 
                         (original_roi[0], original_roi[1]),
                         (original_roi[0] + original_roi[2], original_roi[1] + original_roi[3]), 
                         (0, 0, 255), 3)
            cv2.putText(preview_image, 'Your Selection', 
                       (original_roi[0], original_roi[1] - 15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            
            # ç”»å‡ºè„šæœ¬è®¡ç®—å‡ºçš„16:9æ¡† (ç»¿è‰²)
            cv2.rectangle(preview_image, 
                         (final_roi[0], final_roi[1]),
                         (final_roi[0] + final_roi[2], final_roi[1] + final_roi[3]), 
                         (0, 255, 0), 3)
            cv2.putText(preview_image, 'Final 16:9 Crop', 
                       (final_roi[0], final_roi[1] - 15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # ç¼©æ”¾ä»¥ä¾¿æ˜¾ç¤º
            height, width = preview_image.shape[:2]
            display_height = 800
            display_scale = display_height / height if height > 0 else 1
            display_width = int(width * display_scale)
            display_frame = cv2.resize(preview_image, (display_width, display_height))
            
            # æ·»åŠ è¯´æ˜æ–‡å­—
            cv2.putText(display_frame, "Press any key to start processing...", 
                       (20, display_height - 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
            
            # æ·»åŠ æ¯”ä¾‹ä¿¡æ¯
            aspect_ratio = final_roi[2] / final_roi[3] if final_roi[3] > 0 else 0
            info_text = f"16:9 Ratio: {aspect_ratio:.3f}, Size: {final_roi[2]}x{final_roi[3]}"
            cv2.putText(display_frame, info_text, 
                       (20, 40), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # æ˜¾ç¤ºé¢„è§ˆçª—å£
            window_name = "Final Crop Preview (Red: Your Selection, Green: 16:9 Adjusted)"
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)
            cv2.resizeWindow(window_name, display_width, display_height)
            cv2.imshow(window_name, display_frame)
            
            print("\nğŸ¯ æœ€ç»ˆè£å‰ªæ¡†é¢„è§ˆ:")
            print(f"   çº¢è‰²æ¡†: æ‚¨çš„é€‰æ‹© {original_roi}")
            print(f"   ç»¿è‰²æ¡†: 16:9è°ƒæ•´å {final_roi}")
            print(f"   å®½é«˜æ¯”: {aspect_ratio:.3f} (ç›®æ ‡: 1.778)")
            print("   æŒ‰ä»»æ„é”®å¼€å§‹å¤„ç†...")
            
            cv2.waitKey(0)
            cv2.destroyAllWindows()
            
        except Exception as e:
            logger.warning(f"æ˜¾ç¤ºROIé¢„è§ˆå¤±è´¥: {e}")
            print("âš ï¸ æ— æ³•æ˜¾ç¤ºé¢„è§ˆï¼Œç›´æ¥å¼€å§‹å¤„ç†...")
    
    def scale_roi_for_resolution(self, base_roi: Tuple[int, int, int, int, int, int], 
                                target_width: int, target_height: int) -> Tuple[int, int, int, int]:
        """æ ¹æ®ç›®æ ‡åˆ†è¾¨ç‡ç¼©æ”¾ROI
        
        Args:
            base_roi: (x, y, w, h, base_width, base_height) åŸºå‡†ROIå’ŒåŸºå‡†åˆ†è¾¨ç‡
            target_width: ç›®æ ‡è§†é¢‘å®½åº¦
            target_height: ç›®æ ‡è§†é¢‘é«˜åº¦
            
        Returns:
            (x, y, w, h) ç¼©æ”¾åçš„ROIåæ ‡
        """
        x, y, w, h, base_width, base_height = base_roi
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        width_scale = target_width / base_width
        height_scale = target_height / base_height
        
        # æŒ‰æ¯”ä¾‹ç¼©æ”¾ROIåæ ‡
        scaled_x = int(x * width_scale)
        scaled_y = int(y * height_scale)
        scaled_w = int(w * width_scale)
        scaled_h = int(h * height_scale)
        
        # ç¡®ä¿ç¼©æ”¾åçš„ROIä¸è¶…å‡ºç›®æ ‡è§†é¢‘è¾¹ç•Œ
        scaled_x = max(0, min(scaled_x, target_width - scaled_w))
        scaled_y = max(0, min(scaled_y, target_height - scaled_h))
        
        if scaled_x + scaled_w > target_width:
            scaled_w = target_width - scaled_x
        if scaled_y + scaled_h > target_height:
            scaled_h = target_height - scaled_y
        
        logger.info(f"ROIç¼©æ”¾: åŸºå‡†{base_width}x{base_height} -> ç›®æ ‡{target_width}x{target_height}")
        logger.info(f"  åŸå§‹ROI: ({x}, {y}, {w}, {h})")
        logger.info(f"  ç¼©æ”¾ROI: ({scaled_x}, {scaled_y}, {scaled_w}, {scaled_h})")
        logger.info(f"  ç¼©æ”¾æ¯”ä¾‹: {width_scale:.3f}x{height_scale:.3f}")
        
        return (scaled_x, scaled_y, scaled_w, scaled_h)

# ==================== è¿›åº¦ç®¡ç†å™¨ ====================
class ProgressManager:
    """ç»Ÿä¸€è¿›åº¦ç®¡ç†å™¨"""
    
    def __init__(self, computer_name: str, db_manager: DatabaseManager):
        self.computer_name = computer_name
        self.db_manager = db_manager
        self.progress_file = Path(PROGRESS_FOLDER) / f"progress_{computer_name}.json"
        self.progress_data = self._load_progress()
        
        # ç¡®ä¿è¿›åº¦æ–‡ä»¶å¤¹å­˜åœ¨
        self.progress_file.parent.mkdir(exist_ok=True)
    
    def _load_progress(self) -> Dict[str, Any]:
        """åŠ è½½è¿›åº¦æ•°æ®"""
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                logger.info(f"åŠ è½½è¿›åº¦è®°å½•: {len(data.get('completed', []))} ä¸ªå·²å®Œæˆ")
                return data
            except Exception as e:
                logger.warning(f"åŠ è½½è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
        
        return {
            'completed': [],
            'processing': [],
            'failed': [],
            'roi_settings': None,
            'start_time': None
        }
    
    def save_progress(self):
        """ä¿å­˜è¿›åº¦æ•°æ®"""
        try:
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(self.progress_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")
    
    def is_completed(self, video_path: str) -> bool:
        """æ£€æŸ¥è§†é¢‘æ˜¯å¦å·²å®Œæˆ"""
        video_name = os.path.basename(video_path)
        
        # æ£€æŸ¥æœ¬åœ°è¿›åº¦è®°å½•
        for record in self.progress_data['completed']:
            if isinstance(record, dict):
                if record.get('name') == video_name:
                    return True
            elif record == video_name:
                return True
        
        return False
    
    def mark_completed(self, video_path: str, output_path: str = None, processing_time: float = 0.0):
        """æ ‡è®°ä¸ºå·²å®Œæˆ"""
        video_name = os.path.basename(video_path)
        
        # æ·»åŠ åˆ°å·²å®Œæˆåˆ—è¡¨
        record = {
            'name': video_name,
            'path': video_path,
            'output_path': output_path,
            'processing_time': processing_time,
            'completed_time': datetime.now().isoformat(),
            'computer': self.computer_name
        }
        
        self.progress_data['completed'].append(record)
        
        # ä»å¤„ç†ä¸­ç§»é™¤
        self.progress_data['processing'] = [
            p for p in self.progress_data['processing'] if p != video_name
        ]
        
        self.save_progress()
        logger.info(f"æ ‡è®°å®Œæˆ: {video_name}")
    
    def mark_processing(self, video_path: str):
        """æ ‡è®°ä¸ºå¤„ç†ä¸­"""
        video_name = os.path.basename(video_path)
        if video_name not in self.progress_data['processing']:
            self.progress_data['processing'].append(video_name)
            self.save_progress()
    
    def mark_failed(self, video_path: str, error_msg: str = ""):
        """æ ‡è®°ä¸ºå¤±è´¥"""
        video_name = os.path.basename(video_path)
        
        self.progress_data['failed'].append({
            'name': video_name,
            'error': error_msg,
            'time': datetime.now().isoformat()
        })
        
        # ä»å¤„ç†ä¸­ç§»é™¤
        self.progress_data['processing'] = [
            p for p in self.progress_data['processing'] if p != video_name
        ]
        
        self.save_progress()
        logger.error(f"æ ‡è®°å¤±è´¥: {video_name} - {error_msg}")
    
    def get_statistics(self) -> Dict[str, int]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'completed': len(self.progress_data['completed']),
            'processing': len(self.progress_data['processing']),
            'failed': len(self.progress_data['failed'])
        }
    
    def set_roi_settings(self, roi: Tuple[int, int, int, int, int, int]):
        """ä¿å­˜ROIè®¾ç½®ï¼ˆåŒ…å«åŸºå‡†åˆ†è¾¨ç‡ï¼‰"""
        self.progress_data['roi_settings'] = roi
        self.save_progress()
        x, y, w, h, base_width, base_height = roi
        logger.info(f"ä¿å­˜ROIè®¾ç½®: åŒºåŸŸ({x}, {y}, {w}, {h}), åŸºå‡†åˆ†è¾¨ç‡{base_width}x{base_height}")
    
    def get_roi_settings(self) -> Optional[Tuple[int, int, int, int, int, int]]:
        """è·å–ROIè®¾ç½®ï¼ˆåŒ…å«åŸºå‡†åˆ†è¾¨ç‡ï¼‰"""
        saved_roi = self.progress_data.get('roi_settings')
        if saved_roi and len(saved_roi) == 6:
            return saved_roi
        elif saved_roi and len(saved_roi) == 4:
            # å…¼å®¹æ—§æ ¼å¼ï¼Œå‡è®¾åŸºå‡†åˆ†è¾¨ç‡æ˜¯1080p
            x, y, w, h = saved_roi
            logger.warning("å‘ç°æ—§æ ¼å¼ROIè®¾ç½®ï¼Œå‡è®¾åŸºå‡†åˆ†è¾¨ç‡ä¸º1920x1080")
            return (x, y, w, h, 1920, 1080)
        return None

# ==================== è§†é¢‘å¤„ç†å™¨ ====================
class VideoProcessor:
    """ç»Ÿä¸€è§†é¢‘å¤„ç†å™¨"""
    
    def __init__(self, hardware_info: Dict[str, Any], progress_manager: ProgressManager):
        self.hardware_info = hardware_info
        self.progress_manager = progress_manager
        self.temp_dir = Path("temp_processing")
        self.temp_dir.mkdir(exist_ok=True)
    
    def calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        hash_sha256 = hashlib.sha256()
        try:
            with open(file_path, "rb") as f:
                # è¯»å–æ–‡ä»¶å¼€å¤´ã€ä¸­é—´ã€ç»“å°¾çš„æ ·æœ¬
                file_size = os.path.getsize(file_path)
                chunk_size = 1024 * 1024  # 1MB
                
                # å¼€å¤´
                chunk = f.read(min(chunk_size, file_size))
                hash_sha256.update(chunk)
                
                # ä¸­é—´
                if file_size > chunk_size * 2:
                    f.seek(file_size // 2)
                    chunk = f.read(min(chunk_size, file_size - file_size // 2))
                    hash_sha256.update(chunk)
                
                # ç»“å°¾
                if file_size > chunk_size:
                    f.seek(-min(chunk_size, file_size), 2)
                    chunk = f.read()
                    hash_sha256.update(chunk)
                    
        except Exception as e:
            logger.error(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: {e}")
            return ""
        
        return hash_sha256.hexdigest()
    
    def get_video_info(self, video_path: str) -> Dict[str, Any]:
        """è·å–è§†é¢‘ä¿¡æ¯"""
        try:
            probe_cmd = [
                FFPROBE_PATH, '-v', 'quiet', '-print_format', 'json',
                '-show_format', '-show_streams', video_path
            ]
            
            result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30, encoding='utf-8', errors='ignore')
            
            if result.returncode != 0:
                return {}
            
            data = json.loads(result.stdout)
            video_stream = None
            
            # æŸ¥æ‰¾è§†é¢‘æµ
            for stream in data.get('streams', []):
                if stream.get('codec_type') == 'video':
                    video_stream = stream
                    break
            
            if not video_stream:
                return {}
            
            info = {
                'width': int(video_stream.get('width', 0)),
                'height': int(video_stream.get('height', 0)),
                'duration': float(video_stream.get('duration', 0)),
                'fps': eval(video_stream.get('r_frame_rate', '25/1')),
                'codec': video_stream.get('codec_name', 'unknown'),
                'file_size': os.path.getsize(video_path)
            }
            
            # ä»formatè·å–æ€»æ—¶é•¿
            format_info = data.get('format', {})
            if 'duration' in format_info:
                info['duration'] = float(format_info['duration'])
            
            return info
            
        except Exception as e:
            logger.error(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def should_skip_low_resolution(self, video_path: str) -> Tuple[bool, str]:
        """æ£€æŸ¥æ˜¯å¦åº”è·³è¿‡ä½åˆ†è¾¨ç‡è§†é¢‘"""
        if not SKIP_LOW_RESOLUTION:
            return False, ""
        
        video_info = self.get_video_info(video_path)
        width = video_info.get('width', 0)
        height = video_info.get('height', 0)
        
        if width == 0 or height == 0:
            return False, "æ— æ³•è·å–åˆ†è¾¨ç‡"
        
        if width < MIN_RESOLUTION_WIDTH:
            reason = f"åˆ†è¾¨ç‡({width}x{height})ä½äºæœ€å°è¦æ±‚({MIN_RESOLUTION_WIDTH}pxå®½åº¦)"
            return True, reason
        
        return False, ""
    
    def build_ffmpeg_command(self, input_file: str, output_file: str, 
                           mode: ProcessingMode, roi: Optional[Tuple[int, int, int, int]] = None,
                           cut_head: float = 0, cut_tail: float = 0,
                           segment_duration: float = 0) -> List[str]:
        """æ„å»ºFFmpegå‘½ä»¤"""
        cmd = [FFMPEG_PATH, '-y', '-nostdin']
        
        # è¾“å…¥å‚æ•°
        if cut_head > 0:
            cmd.extend(['-ss', str(cut_head)])
        
        cmd.extend(['-i', input_file])
        
        # è§†é¢‘å¤„ç†å‚æ•°
        video_filters = []
        
        if mode in [ProcessingMode.CROP, ProcessingMode.BOTH] and roi:
            x, y, w, h = roi
            crop_filter = f"crop={w}:{h}:{x}:{y}"
            scale_filter = f"scale={TARGET_RESOLUTION[0]}:{TARGET_RESOLUTION[1]}:force_original_aspect_ratio=disable"
            video_filters.extend([crop_filter, scale_filter])
        
        if video_filters:
            cmd.extend(['-vf', ','.join(video_filters)])
        
        # ç¼–ç å™¨è®¾ç½®
        cmd.extend(['-c:v', self.hardware_info['encoder']])
        
        # ç¼–ç å™¨é€‰é¡¹
        for key, value in self.hardware_info['encoder_options'].items():
            cmd.extend([f'-{key}', str(value)])
        
        # éŸ³é¢‘è®¾ç½®
        cmd.extend(['-c:a', 'aac', '-b:a', '192k'])
        
        # æ—¶é•¿é™åˆ¶
        if cut_tail > 0:
            video_info = self.get_video_info(input_file)
            duration = video_info.get('duration', 0)
            if duration > 0:
                end_time = duration - cut_tail
                cmd.extend(['-t', str(end_time - cut_head)])
        elif segment_duration > 0:
            cmd.extend(['-t', str(segment_duration)])
        
        # è¾“å‡ºè®¾ç½®
        cmd.extend([
            '-movflags', '+faststart',
            '-map_metadata', '-1',
            '-avoid_negative_ts', 'make_zero',
            output_file
        ])
        
        return cmd
    
    def run_ffmpeg_with_progress(self, cmd: List[str], expected_duration: float, 
                                video_name: str) -> bool:
        """è¿è¡ŒFFmpegå¹¶æ˜¾ç¤ºè¿›åº¦"""
        try:
            process = subprocess.Popen(
                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                universal_newlines=True, encoding='utf-8', bufsize=1
            )
            
            with tqdm(total=100, desc=f"å¤„ç†: {video_name[:30]}", 
                     unit='%', leave=False) as pbar:
                
                last_progress = 0
                
                while process.poll() is None:
                    line = process.stderr.readline()
                    if line:
                        progress_info = self._parse_ffmpeg_progress(line)
                        if 'time' in progress_info:
                            current_time = progress_info['time']
                            progress = min(95, (current_time / expected_duration) * 100)
                            
                            if progress > last_progress:
                                pbar.update(progress - last_progress)
                                last_progress = progress
                
                # å®Œæˆæœ€å5%
                if last_progress < 100:
                    pbar.update(100 - last_progress)
            
            if process.returncode == 0:
                logger.info(f"FFmpegå¤„ç†æˆåŠŸ: {video_name}")
                return True
            else:
                stderr_output = process.stderr.read()
                logger.error(f"FFmpegå¤„ç†å¤±è´¥: {video_name} - {stderr_output}")
                return False
                
        except Exception as e:
            logger.error(f"è¿è¡ŒFFmpegå¼‚å¸¸: {e}")
            return False
    
    def _parse_ffmpeg_progress(self, line: str) -> Dict[str, float]:
        """è§£æFFmpegè¿›åº¦è¾“å‡º"""
        info = {}
        patterns = {
            'frame': r'frame=\s*(\d+)',
            'fps': r'fps=\s*([\d\.]+)',
            'time': r'time=\s*(\d+):(\d+):([\d\.]+)',
            'speed': r'speed=\s*([\d\.]+)x'
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, line)
            if match:
                if key == 'time':
                    hours, minutes, seconds = match.groups()
                    info[key] = float(hours) * 3600 + float(minutes) * 60 + float(seconds)
                else:
                    info[key] = float(match.group(1))
        
        return info
    
    def process_video_crop(self, input_path: str, output_path: str, 
                          base_roi: Tuple[int, int, int, int, int, int], 
                          roi_selector: 'ROISelector' = None) -> bool:
        """å¤„ç†è§†é¢‘è£å‰ªï¼Œè‡ªåŠ¨æ ¹æ®è§†é¢‘åˆ†è¾¨ç‡ç¼©æ”¾ROI"""
        try:
            video_info = self.get_video_info(input_path)
            duration = video_info.get('duration', 0)
            video_width = video_info.get('width', 0)
            video_height = video_info.get('height', 0)
            
            if duration <= 0:
                logger.error(f"æ— æ³•è·å–è§†é¢‘æ—¶é•¿: {input_path}")
                return False
            
            if video_width <= 0 or video_height <= 0:
                logger.error(f"æ— æ³•è·å–è§†é¢‘åˆ†è¾¨ç‡: {input_path}")
                return False
            
            # æ ¹æ®å®é™…è§†é¢‘åˆ†è¾¨ç‡ç¼©æ”¾ROI
            if roi_selector:
                actual_roi = roi_selector.scale_roi_for_resolution(base_roi, video_width, video_height)
            else:
                # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ²¡æœ‰roi_selectorï¼Œä½¿ç”¨åŸºç¡€ROIï¼ˆå‰4ä¸ªå€¼ï¼‰
                actual_roi = base_roi[:4]
            
            x, y, w, h, base_width, base_height = base_roi
            print(f"ğŸ“ å¤„ç†è§†é¢‘: {os.path.basename(input_path)} ({video_width}x{video_height})")
            print(f"   åŸºå‡†ROI: ({x}, {y}, {w}, {h}) @ {base_width}x{base_height}")
            print(f"   å®é™…ROI: {actual_roi}")
            
            cmd = self.build_ffmpeg_command(
                input_path, output_path, ProcessingMode.CROP, roi=actual_roi
            )
            
            logger.info(f"å¼€å§‹è£å‰ªå¤„ç†: {os.path.basename(input_path)}")
            return self.run_ffmpeg_with_progress(cmd, duration, os.path.basename(input_path))
            
        except Exception as e:
            logger.error(f"è§†é¢‘è£å‰ªå¤±è´¥: {e}")
            return False
    
    def process_video_trim(self, input_path: str, output_path: str,
                          cut_head: float = 0, cut_tail: float = 0,
                          segment_duration: float = 0) -> bool:
        """å¤„ç†è§†é¢‘åˆ‡å¤´å°¾"""
        try:
            video_info = self.get_video_info(input_path)
            original_duration = video_info.get('duration', 0)
            
            if original_duration <= 0:
                logger.error(f"æ— æ³•è·å–è§†é¢‘æ—¶é•¿: {input_path}")
                return False
            
            # å¦‚æœéœ€è¦åˆ†æ®µå¤„ç†
            if segment_duration > 0 and original_duration > segment_duration:
                return self._process_video_segments(
                    input_path, output_path, cut_head, cut_tail, segment_duration
                )
            
            # å•æ®µå¤„ç†
            effective_duration = original_duration - cut_head - cut_tail
            if effective_duration <= 0:
                logger.error(f"åˆ‡å¤´å°¾åè§†é¢‘æ—¶é•¿æ— æ•ˆ: {effective_duration}")
                return False
            
            cmd = self.build_ffmpeg_command(
                input_path, output_path, ProcessingMode.TRIM,
                cut_head=cut_head, cut_tail=cut_tail
            )
            
            logger.info(f"å¼€å§‹åˆ‡å¤´å°¾å¤„ç†: {os.path.basename(input_path)}")
            return self.run_ffmpeg_with_progress(cmd, effective_duration, os.path.basename(input_path))
            
        except Exception as e:
            logger.error(f"è§†é¢‘åˆ‡å¤´å°¾å¤±è´¥: {e}")
            return False
    
    def _process_video_segments(self, input_path: str, output_path: str,
                               cut_head: float, cut_tail: float, segment_duration: float) -> bool:
        """åˆ†æ®µå¤„ç†è§†é¢‘"""
        try:
            video_info = self.get_video_info(input_path)
            total_duration = video_info.get('duration', 0) - cut_head - cut_tail
            
            segments = []
            current_start = cut_head
            segment_index = 0
            
            # ç”Ÿæˆåˆ†æ®µ
            while current_start < total_duration + cut_head:
                segment_end = min(current_start + segment_duration, total_duration + cut_head)
                
                if segment_end - current_start < 60:  # æœ€åä¸€æ®µå°‘äº1åˆ†é’Ÿï¼Œåˆå¹¶åˆ°å‰ä¸€æ®µ
                    if segments:
                        # æ‰©å±•æœ€åä¸€æ®µ
                        last_segment = segments[-1]
                        segments[-1] = (last_segment[0], segment_end, last_segment[2])
                    break
                
                base_name = os.path.splitext(os.path.basename(output_path))[0]
                segment_path = os.path.join(
                    os.path.dirname(output_path),
                    f"{base_name}_part{segment_index + 1:03d}.mp4"
                )
                
                segments.append((current_start, segment_end, segment_path))
                current_start = segment_end
                segment_index += 1
            
            # å¤„ç†æ¯ä¸ªåˆ†æ®µ
            for start_time, end_time, segment_path in segments:
                duration = end_time - start_time
                
                cmd = [FFMPEG_PATH, '-y', '-nostdin']
                cmd.extend(['-ss', str(start_time)])
                cmd.extend(['-i', input_path])
                cmd.extend(['-t', str(duration)])
                cmd.extend(['-c:v', self.hardware_info['encoder']])
                
                # ç¼–ç å™¨é€‰é¡¹
                for key, value in self.hardware_info['encoder_options'].items():
                    cmd.extend([f'-{key}', str(value)])
                
                cmd.extend(['-c:a', 'aac', '-b:a', '192k'])
                cmd.extend(['-movflags', '+faststart'])
                cmd.append(segment_path)
                
                logger.info(f"å¤„ç†åˆ†æ®µ {len(segments)}: {os.path.basename(segment_path)}")
                
                if not self.run_ffmpeg_with_progress(cmd, duration, os.path.basename(segment_path)):
                    logger.error(f"åˆ†æ®µå¤„ç†å¤±è´¥: {segment_path}")
                    return False
            
            logger.info(f"åˆ†æ®µå¤„ç†å®Œæˆï¼Œå…± {len(segments)} ä¸ªåˆ†æ®µ")
            return True
            
        except Exception as e:
            logger.error(f"åˆ†æ®µå¤„ç†å¤±è´¥: {e}")
            return False

# ==================== æµæ°´çº¿ç®¡ç†å™¨ ====================
class VideoPipelineManager:
    """è§†é¢‘å¤„ç†æµæ°´çº¿ç®¡ç†å™¨"""
    
    def __init__(self, max_concurrent: int = 4):
        self.max_concurrent = max_concurrent
        self.tasks: Dict[str, VideoTask] = {}
        self.cache_queue = queue.Queue()
        self.check_queue = queue.Queue()
        self.process_queue = queue.Queue()
        
        self.workers = []
        self.shutdown_event = threading.Event()
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        self._start_workers()
    
    def _start_workers(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹"""
        # ç¼“å­˜å·¥ä½œçº¿ç¨‹
        cache_worker = threading.Thread(target=self._cache_worker, daemon=True)
        cache_worker.start()
        self.workers.append(cache_worker)
        
        # æ£€æŸ¥å·¥ä½œçº¿ç¨‹
        check_worker = threading.Thread(target=self._check_worker, daemon=True)
        check_worker.start()
        self.workers.append(check_worker)
        
        # å¤„ç†å·¥ä½œçº¿ç¨‹
        for i in range(self.max_concurrent):
            process_worker = threading.Thread(target=self._process_worker, daemon=True)
            process_worker.start()
            self.workers.append(process_worker)
    
    def add_task(self, video_path: str, mode: ProcessingMode, **kwargs) -> str:
        """æ·»åŠ å¤„ç†ä»»åŠ¡"""
        task_id = f"task_{int(time.time() * 1000)}_{len(self.tasks)}"
        
        task = VideoTask(
            video_path=video_path,
            task_id=task_id,
            mode=mode,
            **kwargs
        )
        
        self.tasks[task_id] = task
        
        # æ·»åŠ åˆ°ç¼“å­˜é˜Ÿåˆ—
        if ENABLE_CACHE:
            self.cache_queue.put(task_id)
        else:
            # ç›´æ¥è¿›å…¥æ£€æŸ¥é˜Ÿåˆ—
            task.update_stage(PipelineStage.CACHED)
            self.check_queue.put(task_id)
        
        return task_id
    
    def _cache_worker(self):
        """ç¼“å­˜å·¥ä½œçº¿ç¨‹"""
        while not self.shutdown_event.is_set():
            try:
                task_id = self.cache_queue.get(timeout=1)
                task = self.tasks.get(task_id)
                
                if not task:
                    continue
                
                task.update_stage(PipelineStage.CACHING)
                
                # æ‰§è¡Œç¼“å­˜é€»è¾‘ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
                time.sleep(0.1)  # æ¨¡æ‹Ÿç¼“å­˜æ—¶é—´
                
                task.update_stage(PipelineStage.CACHED)
                self.check_queue.put(task_id)
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"ç¼“å­˜å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
    
    def _check_worker(self):
        """æ£€æŸ¥å·¥ä½œçº¿ç¨‹"""
        while not self.shutdown_event.is_set():
            try:
                task_id = self.check_queue.get(timeout=1)
                task = self.tasks.get(task_id)
                
                if not task:
                    continue
                
                task.update_stage(PipelineStage.CHECKING)
                
                # æ‰§è¡Œå»é‡æ£€æŸ¥é€»è¾‘ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
                time.sleep(0.1)  # æ¨¡æ‹Ÿæ£€æŸ¥æ—¶é—´
                
                # å‡è®¾æ²¡æœ‰é‡å¤
                self.process_queue.put(task_id)
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"æ£€æŸ¥å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
    
    def _process_worker(self):
        """å¤„ç†å·¥ä½œçº¿ç¨‹"""
        while not self.shutdown_event.is_set():
            try:
                task_id = self.process_queue.get(timeout=1)
                task = self.tasks.get(task_id)
                
                if not task:
                    continue
                
                task.update_stage(PipelineStage.PROCESSING)
                
                # æ‰§è¡Œå®é™…çš„è§†é¢‘å¤„ç†
                # è¿™é‡Œéœ€è¦æ ¹æ®task.modeè°ƒç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°
                
                task.update_stage(PipelineStage.COMPLETED)
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"å¤„ç†å·¥ä½œçº¿ç¨‹å¼‚å¸¸: {e}")
    
    def wait_completion(self, timeout: Optional[float] = None) -> bool:
        """ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ"""
        start_time = time.time()
        
        while True:
            if timeout and time.time() - start_time > timeout:
                return False
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆ
            all_done = True
            for task in self.tasks.values():
                if task.stage not in [PipelineStage.COMPLETED, PipelineStage.FAILED, 
                                    PipelineStage.CANCELLED, PipelineStage.DUPLICATE]:
                    all_done = False
                    break
            
            if all_done:
                return True
            
            time.sleep(1)
    
    def get_statistics(self) -> Dict[str, int]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        for stage in PipelineStage:
            stats[stage.value] = sum(1 for task in self.tasks.values() if task.stage == stage)
        return stats
    
    def shutdown(self):
        """å…³é—­æµæ°´çº¿"""
        self.shutdown_event.set()

# ==================== ä¸»å¤„ç†å™¨ ====================
class UnifiedVideoProcessor:
    """ç»Ÿåˆè§†é¢‘å¤„ç†å™¨ - ä¸»æ§åˆ¶å™¨ï¼ˆå¢å¼ºç¨³å®šæ€§ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self):
        self.computer_name = socket.gethostname()
        self.mode = ProcessingMode(PROCESSING_MODE)
        self.batch_id = f"batch_{int(time.time())}"
        self.start_time = time.time()
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.hardware_detector = HardwareDetector()
        self.db_manager = DatabaseManager()
        self.cache_manager = SmartCacheManager(self.db_manager) if ENABLE_CACHE else None
        self.progress_manager = ProgressManager(self.computer_name, self.db_manager)
        self.roi_selector = ROISelector()
        
        # æ–°å¢ï¼šå¥åº·ç›‘æ§å’Œåˆ†å¸ƒå¼ç®¡ç†
        self.memory_monitor = MemoryHealthMonitor()
        self.task_manager = DistributedTaskManager(self.db_manager, self.computer_name)
        
        # æ£€æµ‹ç¡¬ä»¶èƒ½åŠ›
        self.hardware_info = self.hardware_detector.detect_hardware_capabilities()
        
        # åˆ›å»ºè§†é¢‘å¤„ç†å™¨
        self.video_processor = VideoProcessor(self.hardware_info, self.progress_manager)
        
        # åˆ›å»ºæµæ°´çº¿ç®¡ç†å™¨
        self.pipeline_manager = VideoPipelineManager(
            max_concurrent=self.hardware_info['max_parallel']
        )
        
        # é”™è¯¯æ¢å¤å’Œç›‘æ§
        self.error_count = 0
        self.max_consecutive_errors = 10
        self.last_successful_time = time.time()
        self.shutdown_event = threading.Event()
        
        # æ³¨å†Œä¼˜é›…å…³é—­
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        logger.info(f"ğŸš€ åˆå§‹åŒ–å®Œæˆ - æ¨¡å¼: {self.mode.value}, ç¡¬ä»¶: {self.hardware_info['encoder_type']}")
        logger.info(f"ğŸ“Š å†…å­˜ç›‘æ§: å¯ç”¨, åˆ†å¸ƒå¼å¤„ç†: {'å¯ç”¨' if ENABLE_DISTRIBUTED_PROCESSING else 'ç¦ç”¨'}")
    
    def _signal_handler(self, signum, frame):
        """ä¼˜é›…å…³é—­ä¿¡å·å¤„ç†å™¨"""
        logger.info(f"ğŸ“¡ æ”¶åˆ°å…³é—­ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
        self.shutdown_event.set()
        self.graceful_shutdown()
    
    def graceful_shutdown(self):
        """ä¼˜é›…å…³é—­å¤„ç†å™¨"""
        logger.info("ğŸ›‘ å¼€å§‹ä¼˜é›…å…³é—­è§†é¢‘å¤„ç†å™¨...")
        
        try:
            # å…³é—­å„ä¸ªç»„ä»¶
            if hasattr(self, 'pipeline_manager'):
                self.pipeline_manager.shutdown()
            
            if hasattr(self, 'task_manager'):
                self.task_manager.shutdown()
            
            if hasattr(self, 'cache_manager') and self.cache_manager:
                # ç¼“å­˜ç®¡ç†å™¨çš„å…³é—­é€»è¾‘
                pass
            
            # æœ€ç»ˆç»Ÿè®¡
            if hasattr(self, 'memory_monitor'):
                stats = self.memory_monitor.get_memory_stats()
                logger.info(f"ğŸ æœ€ç»ˆç»Ÿè®¡: å¤„ç†{stats.get('processed_count', 0)}ä¸ªè§†é¢‘, "
                           f"è¿è¡Œ{stats.get('uptime_hours', 0):.1f}å°æ—¶, "
                           f"å³°å€¼å†…å­˜{stats.get('max_memory_mb', 0):.0f}MB")
            
            logger.info("âœ… ä¼˜é›…å…³é—­å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å…³é—­è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        
        sys.exit(0)
    
    def find_video_files(self, directory: str) -> List[str]:
        """æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶"""
        video_files = []
        
        try:
            for ext in SUPPORTED_VIDEO_FORMATS:
                pattern = os.path.join(directory, f'*{ext}')
                files = glob.glob(pattern, recursive=False)
                video_files.extend(files)
                
                # ä¹Ÿæœç´¢å¤§å†™æ‰©å±•å
                pattern_upper = os.path.join(directory, f'*{ext.upper()}')
                files_upper = glob.glob(pattern_upper, recursive=False)
                video_files.extend(files_upper)
            
            # å»é‡å¹¶æ’åº
            video_files = list(set(video_files))
            video_files.sort()
            
            logger.info(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            return video_files
            
        except Exception as e:
            logger.error(f"æœç´¢è§†é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def setup_roi_for_crop_mode(self, video_files: List[str]) -> Optional[Tuple[int, int, int, int, int, int]]:
        """ä¸ºè£å‰ªæ¨¡å¼è®¾ç½®ROI"""
        if self.mode not in [ProcessingMode.CROP, ProcessingMode.BOTH]:
            return None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„ROIè®¾ç½®
        saved_roi = self.progress_manager.get_roi_settings()
        if saved_roi:
            logger.info(f"ä½¿ç”¨ä¿å­˜çš„ROIè®¾ç½®: {saved_roi}")
            if len(saved_roi) == 6:
                x, y, w, h, base_width, base_height = saved_roi
                print(f"å‘ç°ä¿å­˜çš„ROIè®¾ç½®: åŒºåŸŸ({x}, {y}, {w}, {h}) @ {base_width}x{base_height}")
            else:
                print(f"å‘ç°ä¿å­˜çš„ROIè®¾ç½®: {saved_roi}")
            print("æŒ‰å›è½¦é”®ä½¿ç”¨ä¿å­˜çš„è®¾ç½®ï¼Œæˆ–è¾“å…¥ 'r' é‡æ–°é€‰æ‹©: ", end="")
            user_input = input().strip().lower()
            
            if user_input != 'r':
                return saved_roi
        
        # é€‰æ‹©ROI
        if not video_files:
            logger.error("æ²¡æœ‰è§†é¢‘æ–‡ä»¶å¯ç”¨äºROIé€‰æ‹©")
            return None
        
        print(f"ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘è¿›è¡ŒROIé€‰æ‹©: {os.path.basename(video_files[0])}")
        roi = self.roi_selector.select_roi_for_video(video_files[0])
        
        if roi:
            self.progress_manager.set_roi_settings(roi)
            logger.info(f"ROIè®¾ç½®å®Œæˆ: {roi}")
            x, y, w, h, base_width, base_height = roi
            print(f"âœ… ROIè®¾ç½®å®Œæˆ:")
            print(f"   è£å‰ªåŒºåŸŸ: ({x}, {y}, {w}, {h})")
            print(f"   åŸºå‡†åˆ†è¾¨ç‡: {base_width}x{base_height}")
            print(f"   å°†è‡ªåŠ¨ç¼©æ”¾åˆ°å…¶ä»–åˆ†è¾¨ç‡çš„ç›¸åº”ä½ç½®")
        
        return roi
    
    def filter_videos(self, video_files: List[str]) -> List[str]:
        """è¿‡æ»¤è§†é¢‘æ–‡ä»¶"""
        filtered_files = []
        skipped_count = 0
        
        for video_path in video_files:
            # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
            if self.progress_manager.is_completed(video_path):
                logger.info(f"è·³è¿‡å·²å®Œæˆ: {os.path.basename(video_path)}")
                continue
            
            # æ£€æŸ¥ä½åˆ†è¾¨ç‡
            should_skip, reason = self.video_processor.should_skip_low_resolution(video_path)
            if should_skip:
                logger.info(f"è·³è¿‡ä½åˆ†è¾¨ç‡: {os.path.basename(video_path)} - {reason}")
                skipped_count += 1
                
                # ç§»åŠ¨åˆ°æŒ‡å®šç›®å½•
                if SKIP_VIDEOS_MOVE_DIR and os.path.exists(SKIP_VIDEOS_MOVE_DIR):
                    try:
                        dest_path = os.path.join(SKIP_VIDEOS_MOVE_DIR, os.path.basename(video_path))
                        shutil.move(video_path, dest_path)
                        logger.info(f"å·²ç§»åŠ¨è·³è¿‡çš„è§†é¢‘: {dest_path}")
                    except Exception as e:
                        logger.warning(f"ç§»åŠ¨è·³è¿‡è§†é¢‘å¤±è´¥: {e}")
                continue
            
            # ğŸ” ã€å…³é”®ã€‘å¤„ç†å‰æ•°æ®åº“æŸ¥é‡æ£€æŸ¥ - ä½¿ç”¨å¢å¼ºæŸ¥é‡
            if self.db_manager.is_enabled:
                logger.info(f"ğŸ” å¤„ç†å‰æ•°æ®åº“æŸ¥é‡: {os.path.basename(video_path)}")
                is_duplicate, message = self.db_manager.enhanced_duplicate_check(video_path)
                
                if is_duplicate:
                    logger.info(f"âœ‹ å¤„ç†å‰å‘ç°é‡å¤ï¼Œè·³è¿‡: {os.path.basename(video_path)} - {message}")
                    continue
                else:
                    logger.debug(f"ğŸ“ å¤„ç†å‰æŸ¥é‡é€šè¿‡: {os.path.basename(video_path)} - {message}")
            
            filtered_files.append(video_path)
        
        logger.info(f"è¿‡æ»¤å®Œæˆ: {len(filtered_files)} ä¸ªå¾…å¤„ç†, {skipped_count} ä¸ªè·³è¿‡")
        return filtered_files
    
    def process_video_file(self, video_path: str, roi: Optional[Tuple[int, int, int, int]] = None) -> bool:
        """å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼ˆå¢å¼ºç¨³å®šæ€§ç‰ˆæœ¬ï¼‰"""
        video_name = os.path.basename(video_path)
        original_video_path = video_path  # ğŸ”‘ ä¿å­˜åŸå§‹è·¯å¾„ï¼Œç”¨äºæ•°æ®åº“è®°å½•
        
        try:
            # 1. åˆ†å¸ƒå¼ä»»åŠ¡å£°æ˜
            if not self.task_manager.claim_video_task(video_path):
                logger.info(f"ğŸ”’ è§†é¢‘å·²è¢«å…¶ä»–ç”µè„‘å¤„ç†: {video_name}")
                return False  # è¢«å…¶ä»–ç”µè„‘é”å®šï¼Œè·³è¿‡
            
            base_name = os.path.splitext(video_name)[0]
            
            # 2. è¶…æ—¶æ£€æŸ¥
            if self.shutdown_event.is_set():
                logger.info("ğŸ›‘ æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œåœæ­¢å¤„ç†")
                return False
            
            # 3. å†…å­˜æ£€æŸ¥å’Œæ¸…ç†
            if self.memory_monitor.should_cleanup_memory():
                freed_mb = self.memory_monitor.cleanup_memory()
                logger.info(f"ğŸ§¹ é¢„å¤„ç†å†…å­˜æ¸…ç†: é‡Šæ”¾ {freed_mb:.1f}MB")
            
            # 4. æ™ºèƒ½ç¼“å­˜å¤„ç†ï¼šä½¿ç”¨ç¼“å­˜è·¯å¾„è¿›è¡Œå¤„ç†ï¼Œä½†æ•°æ®åº“è®°å½•ä½¿ç”¨åŸå§‹è·¯å¾„
            actual_processing_path = video_path  # é»˜è®¤ä½¿ç”¨åŸå§‹è·¯å¾„
            
            if self.cache_manager and self.cache_manager.is_enabled:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜ç‰ˆæœ¬
                cached_path = self.cache_manager.get_cached_path(video_path)
                if cached_path:
                    logger.info(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜ç‰ˆæœ¬: {video_name}")
                    actual_processing_path = cached_path  # ğŸ¯ ä½¿ç”¨ç¼“å­˜è·¯å¾„è¿›è¡Œå¤„ç†
                else:
                    logger.debug(f"ğŸ“ ä½¿ç”¨åŸå§‹æ–‡ä»¶: {video_name}")
            
            # 5. æ ‡è®°ä¸ºå¤„ç†ä¸­
            self.progress_manager.mark_processing(original_video_path)
            self.memory_monitor.update_processed_count()
            
            start_time = time.time()
            success = False
            
            # 6. å¤„ç†è¶…æ—¶ä¿æŠ¤
            processing_timeout = MAX_PROCESSING_TIME_HOURS * 3600
            
            logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†: {video_name}")
            logger.info(f"   ğŸ“‚ åŸå§‹è·¯å¾„: {original_video_path}")
            logger.info(f"   ğŸ”§ å¤„ç†è·¯å¾„: {actual_processing_path}")
            
            if self.mode == ProcessingMode.CROP:
                if not roi:
                    logger.error("è£å‰ªæ¨¡å¼éœ€è¦ROIå‚æ•°")
                    return False
                
                output_path = os.path.join(OUTPUT_DIR, f"{base_name}_cropped.mp4")
                success = self.video_processor.process_video_crop(actual_processing_path, output_path, roi, self.roi_selector)
            
            elif self.mode == ProcessingMode.TRIM:
                output_path = os.path.join(OUTPUT_DIR, f"{base_name}_trimmed.mp4")
                success = self.video_processor.process_video_trim(
                    actual_processing_path, output_path, CUT_HEAD_SECONDS, CUT_TAIL_SECONDS, SEGMENT_DURATION
                )
            
            elif self.mode == ProcessingMode.BOTH:
                if not roi:
                    logger.error("æ··åˆæ¨¡å¼éœ€è¦ROIå‚æ•°")
                    return False
                
                # å…ˆè£å‰ª
                temp_cropped = self.video_processor.temp_dir / f"{base_name}_temp_cropped.mp4"
                crop_success = self.video_processor.process_video_crop(actual_processing_path, str(temp_cropped), roi, self.roi_selector)
                
                if crop_success:
                    # å†åˆ‡å¤´å°¾
                    output_path = os.path.join(OUTPUT_DIR, f"{base_name}_processed.mp4")
                    success = self.video_processor.process_video_trim(
                        str(temp_cropped), output_path, CUT_HEAD_SECONDS, CUT_TAIL_SECONDS, SEGMENT_DURATION
                    )
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        temp_cropped.unlink()
                    except Exception:
                        pass
            
            processing_time = time.time() - start_time
            
            # 6. å¤„ç†ç»“æœå¤„ç†
            if success:
                # æˆåŠŸè®¡æ•°å’Œæ¢å¤
                self.error_count = 0
                self.last_successful_time = time.time()
                
                # æ ‡è®°ä¸ºå®Œæˆ
                self.progress_manager.mark_completed(original_video_path, output_path, processing_time)
                
                # ğŸ“ å…³é”®åŠŸèƒ½ï¼šå†™å…¥çœŸå®çš„11ä¸ªå­—æ®µåˆ°æ•°æ®åº“ - ä½¿ç”¨åŸå§‹è·¯å¾„
                if self.db_manager.is_enabled:
                    logger.info(f"ğŸ¯ å¼€å§‹å†™å…¥æ•°æ®åº“çœŸå®ä¿¡æ¯: {video_name}")
                    logger.info(f"   ğŸ“‚ æ•°æ®åº“è®°å½•è·¯å¾„: {original_video_path}")
                    logger.info(f"   ğŸ”§ å®é™…å¤„ç†è·¯å¾„: {actual_processing_path}")
                    
                    # ğŸ”‘ å…³é”®ä¿®å¤ï¼šä½¿ç”¨åŸå§‹è·¯å¾„è¿›è¡Œæ•°æ®åº“è®°å½•ï¼Œç¡®ä¿å“ˆå¸Œè®¡ç®—ä½¿ç”¨å­˜åœ¨çš„æ–‡ä»¶
                    success_db = self.db_manager.record_processing_complete(
                        video_path=original_video_path,  # ğŸ¯ ä½¿ç”¨åŸå§‹è·¯å¾„ï¼Œä¸æ˜¯ç¼“å­˜è·¯å¾„
                        output_path=output_path, 
                        processing_time=processing_time,
                        log_path=None
                    )
                    
                    if success_db:
                        logger.info(f"âœ… æ•°æ®åº“è®°å½•æˆåŠŸ: {video_name}")
                    else:
                        logger.warning(f"âš ï¸ æ•°æ®åº“è®°å½•å¤±è´¥: {video_name}")
                        # æ•°æ®åº“è®°å½•å¤±è´¥ä¸å½±å“å¤„ç†æˆåŠŸçŠ¶æ€
                
                logger.info(f"âœ… å¤„ç†æˆåŠŸ: {video_name} ({processing_time:.1f}s)")
                return True
            else:
                # é”™è¯¯è®¡æ•°
                self.error_count += 1
                
                self.progress_manager.mark_failed(original_video_path, "å¤„ç†å¤±è´¥")
                
                # ä¸è®°å½•å¤±è´¥åˆ°æ•°æ®åº“ï¼Œåªè®°å½•æˆåŠŸçš„å¤„ç†ç»“æœ
                
                logger.error(f"âŒ å¤„ç†å¤±è´¥: {video_name}")
                return False
                
        except Exception as e:
            # é”™è¯¯è®¡æ•°å’Œæ¢å¤æ£€æŸ¥
            self.error_count += 1
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
            if AUTO_RESTART_ON_ERROR and self.error_count >= self.max_consecutive_errors:
                logger.error(f"ğŸš¨ è¿ç»­é”™è¯¯è¾¾åˆ°é˜ˆå€¼ ({self.max_consecutive_errors})ï¼Œå‡†å¤‡é‡å¯...")
                # è¿™é‡Œå¯ä»¥å®ç°é‡å¯é€»è¾‘æˆ–é€šçŸ¥ç®¡ç†å‘˜
            
            self.progress_manager.mark_failed(original_video_path, str(e))
            
            # ä¸è®°å½•å¼‚å¸¸åˆ°æ•°æ®åº“ï¼Œåªè®°å½•æˆåŠŸçš„å¤„ç†ç»“æœ
            
            logger.error(f"âŒ å¤„ç†å¼‚å¸¸: {video_path} - {e}")
            return False
        
        finally:
            # 7. æ¸…ç†å’Œé‡Šæ”¾èµ„æº
            try:
                # é‡Šæ”¾åˆ†å¸ƒå¼ä»»åŠ¡é”
                self.task_manager.release_video_task(original_video_path)
                
                # å¤„ç†åå†…å­˜æ£€æŸ¥
                if self.memory_monitor.should_cleanup_memory():
                    freed_mb = self.memory_monitor.cleanup_memory()
                    logger.debug(f"ğŸ§¹ åå¤„ç†å†…å­˜æ¸…ç†: é‡Šæ”¾ {freed_mb:.1f}MB")
                
            except Exception as cleanup_e:
                logger.warning(f"âš ï¸ æ¸…ç†èµ„æºæ—¶å‡ºç°å¼‚å¸¸: {cleanup_e}")
    
    def process_batch(self, video_files: List[str], roi: Optional[Tuple[int, int, int, int]] = None):
        """æ‰¹é‡å¤„ç†è§†é¢‘ï¼ˆå¢å¼ºå¤§è§„æ¨¡å¤„ç†èƒ½åŠ›ï¼‰"""
        if not video_files:
            logger.info("æ²¡æœ‰éœ€è¦å¤„ç†çš„è§†é¢‘æ–‡ä»¶")
            return
        
        total_videos = len(video_files)
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {total_videos} ä¸ªè§†é¢‘æ–‡ä»¶")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        # å¤§æ•°æ®é›†åˆ†æ‰¹å¤„ç†
        if total_videos > BATCH_SIZE:
            logger.info(f"ğŸ“¦ å¤§æ•°æ®é›†æ£€æµ‹ï¼Œå°†åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹ {BATCH_SIZE} ä¸ªè§†é¢‘")
            return self._process_large_batch(video_files, roi)
        
        # åˆå§‹åŒ–æ‰¹æ¬¡ç»Ÿè®¡
        batch_start_time = time.time()
        success_count = 0
        failed_count = 0
        skipped_count = 0
        
        # é¢„åŠ è½½ç¼“å­˜
        if self.cache_manager:
            logger.info("ğŸš€ å¯åŠ¨æ™ºèƒ½é¢„åŠ è½½...")
            for i, video_path in enumerate(video_files[:PRELOAD_COUNT]):
                self.cache_manager.start_async_download(video_path, priority=-i)
        
        # åˆ†å¸ƒå¼å¤„ç†ï¼šæ¸…ç†è¿‡æœŸé”
        if ENABLE_DISTRIBUTED_PROCESSING:
            self.task_manager.cleanup_expired_locks()
        
        # åˆ›å»ºè¿›åº¦æ¡
        with tqdm(total=total_videos, desc="ğŸ¬ å¤„ç†è¿›åº¦", unit="video", 
                 bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:
            
            # è®¡ç®—æœ€ä¼˜å¹¶è¡Œæ•°
            max_workers = min(self.hardware_info['max_parallel'], total_videos, 32)  # é™åˆ¶æœ€å¤§32å¹¶å‘
            
            logger.info(f"âš¡ ä½¿ç”¨ {max_workers} ä¸ªå¹¶è¡Œå·¥ä½œçº¿ç¨‹")
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_video = {
                    executor.submit(self.process_video_file, video_path, roi): video_path
                    for video_path in video_files
                }
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                processed_count = 0
                for future in concurrent.futures.as_completed(future_to_video):
                    if self.shutdown_event.is_set():
                        logger.info("ğŸ›‘ æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œç»ˆæ­¢æ‰¹é‡å¤„ç†")
                        break
                    
                    video_path = future_to_video[future]
                    video_name = os.path.basename(video_path)
                    
                    try:
                        result = future.result(timeout=MAX_PROCESSING_TIME_HOURS * 3600)
                        if result is True:
                            success_count += 1
                        elif result is False:
                            # False å¯èƒ½è¡¨ç¤ºè¢«å…¶ä»–ç”µè„‘å¤„ç†æˆ–è·³è¿‡
                            skipped_count += 1
                        else:
                            failed_count += 1
                            
                    except concurrent.futures.TimeoutError:
                        logger.error(f"â° å¤„ç†è¶…æ—¶: {video_name}")
                        failed_count += 1
                    except Exception as e:
                        logger.error(f"âŒ ä»»åŠ¡å¼‚å¸¸: {video_name} - {e}")
                        failed_count += 1
                    
                    processed_count += 1
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    current_success_rate = (success_count / processed_count * 100) if processed_count > 0 else 0
                    pbar.update(1)
                    pbar.set_postfix({
                        'âœ…æˆåŠŸ': success_count,
                        'âŒå¤±è´¥': failed_count, 
                        'â­ï¸è·³è¿‡': skipped_count,
                        'ğŸ“ŠæˆåŠŸç‡': f"{current_success_rate:.1f}%",
                        'ğŸ§ å†…å­˜': f"{self.memory_monitor.get_memory_stats().get('current_memory_mb', 0):.0f}MB"
                    })
                    
                    # å®šæœŸå¥åº·æ£€æŸ¥
                    if processed_count % 50 == 0:
                        self._health_check_during_batch(processed_count, total_videos)
        
        # æ‰¹æ¬¡å®Œæˆç»Ÿè®¡
        batch_duration = time.time() - batch_start_time
        total_processed = success_count + failed_count + skipped_count
        
        self._log_batch_completion(total_processed, success_count, failed_count, 
                                 skipped_count, batch_duration)
    
    def _process_large_batch(self, video_files: List[str], roi: Optional[Tuple[int, int, int, int]] = None):
        """å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆåˆ†æ‰¹å¤„ç†ï¼‰"""
        total_videos = len(video_files)
        total_batches = (total_videos + BATCH_SIZE - 1) // BATCH_SIZE
        
        logger.info(f"ğŸ“Š å¤§è§„æ¨¡å¤„ç†ç»Ÿè®¡: {total_videos} ä¸ªè§†é¢‘, {total_batches} æ‰¹æ¬¡, æ¯æ‰¹ {BATCH_SIZE} ä¸ª")
        
        overall_success = 0
        overall_failed = 0
        overall_skipped = 0
        
        for batch_idx in range(total_batches):
            if self.shutdown_event.is_set():
                logger.info("ğŸ›‘ æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œç»ˆæ­¢å¤§è§„æ¨¡å¤„ç†")
                break
            
            start_idx = batch_idx * BATCH_SIZE
            end_idx = min(start_idx + BATCH_SIZE, total_videos)
            batch_files = video_files[start_idx:end_idx]
            
            logger.info(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} "
                       f"({len(batch_files)} ä¸ªè§†é¢‘, ç´¢å¼• {start_idx}-{end_idx-1})")
            
            # æ‰¹æ¬¡é—´å†…å­˜å¼ºåˆ¶æ¸…ç†
            if batch_idx > 0:
                freed_mb = self.memory_monitor.cleanup_memory(force=True)
                logger.info(f"ğŸ§¹ æ‰¹æ¬¡é—´å†…å­˜æ¸…ç†: é‡Šæ”¾ {freed_mb:.1f}MB")
                time.sleep(2)  # çŸ­æš‚ä¼‘æ¯
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡
            batch_start = time.time()
            self.process_batch(batch_files, roi)  # é€’å½’è°ƒç”¨ï¼Œä½†ä¸ä¼šå†è¿›å…¥å¤§æ‰¹æ¬¡é€»è¾‘
            batch_duration = time.time() - batch_start
            
            # æ‰¹æ¬¡å®Œæˆç»Ÿè®¡ï¼ˆè¿™é‡Œéœ€è¦è·å–å®é™…çš„æˆåŠŸ/å¤±è´¥æ•°ï¼Œç®€åŒ–å¤„ç†ï¼‰
            logger.info(f"âœ… æ‰¹æ¬¡ {batch_idx + 1} å®Œæˆï¼Œè€—æ—¶ {batch_duration:.1f}ç§’")
            
            # æ‰¹æ¬¡é—´å¥åº·æ£€æŸ¥
            self._health_check_between_batches(batch_idx + 1, total_batches)
        
        logger.info(f"ğŸ å¤§è§„æ¨¡å¤„ç†å®Œæˆ: {total_batches} æ‰¹æ¬¡å…¨éƒ¨å¤„ç†å®Œæ¯•")
    
    def _health_check_during_batch(self, processed: int, total: int):
        """æ‰¹æ¬¡å¤„ç†æœŸé—´çš„å¥åº·æ£€æŸ¥"""
        try:
            stats = self.memory_monitor.get_memory_stats()
            progress_percent = (processed / total * 100) if total > 0 else 0
            
            logger.info(f"ğŸ¥ å¥åº·æ£€æŸ¥ [{processed}/{total}] "
                       f"è¿›åº¦ {progress_percent:.1f}%, "
                       f"å†…å­˜ {stats.get('current_memory_mb', 0):.0f}MB, "
                       f"è¿è¡Œ {stats.get('uptime_hours', 0):.1f}h")
            
            # æ£€æŸ¥é”™è¯¯ç‡
            if hasattr(self, 'error_count') and processed > 50:
                error_rate = (self.error_count / processed) * 100
                if error_rate > 20:  # é”™è¯¯ç‡è¶…è¿‡20%
                    logger.warning(f"âš ï¸ é«˜é”™è¯¯ç‡è­¦å‘Š: {error_rate:.1f}%")
                    
        except Exception as e:
            logger.warning(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
    
    def _health_check_between_batches(self, current_batch: int, total_batches: int):
        """æ‰¹æ¬¡é—´çš„å¥åº·æ£€æŸ¥"""
        try:
            stats = self.memory_monitor.get_memory_stats()
            
            logger.info(f"ğŸ”„ æ‰¹æ¬¡é—´æ£€æŸ¥ [{current_batch}/{total_batches}] "
                       f"å†…å­˜å³°å€¼ {stats.get('max_memory_mb', 0):.0f}MB, "
                       f"æ¸…ç†æ¬¡æ•° {stats.get('cleanup_count', 0)}")
            
            # åˆ†å¸ƒå¼é”æ¸…ç†
            if ENABLE_DISTRIBUTED_PROCESSING and current_batch % 5 == 0:
                self.task_manager.cleanup_expired_locks()
                
        except Exception as e:
            logger.warning(f"æ‰¹æ¬¡é—´æ£€æŸ¥å¼‚å¸¸: {e}")
    
    def _log_batch_completion(self, total: int, success: int, failed: int, skipped: int, duration: float):
        """è®°å½•æ‰¹æ¬¡å®Œæˆç»Ÿè®¡"""
        success_rate = (success / total * 100) if total > 0 else 0
        avg_time = (duration / total) if total > 0 else 0
        
        logger.info(f"ğŸ¯ æ‰¹é‡å¤„ç†å®Œæˆç»Ÿè®¡:")
        logger.info(f"   æ€»è®¡: {total} ä¸ªè§†é¢‘")
        logger.info(f"   âœ… æˆåŠŸ: {success} ({success_rate:.1f}%)")
        logger.info(f"   âŒ å¤±è´¥: {failed}")
        logger.info(f"   â­ï¸ è·³è¿‡: {skipped}")
        logger.info(f"   â±ï¸ æ€»è€—æ—¶: {duration:.1f}ç§’")
        logger.info(f"   ğŸ“Š å¹³å‡: {avg_time:.1f}ç§’/è§†é¢‘")
        
        # è·å–å†…å­˜ç»Ÿè®¡
        stats = self.memory_monitor.get_memory_stats()
        logger.info(f"   ğŸ§  å†…å­˜å³°å€¼: {stats.get('max_memory_mb', 0):.0f}MB")
        logger.info(f"   ğŸ§¹ æ¸…ç†æ¬¡æ•°: {stats.get('cleanup_count', 0)}")
        
        print(f"\nğŸ¬ æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"   ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}% ({success}/{total})")
        print(f"   â±ï¸ å¤„ç†é€Ÿåº¦: {avg_time:.1f}ç§’/è§†é¢‘")
        print(f"   ğŸ§  å†…å­˜ç®¡ç†: {stats.get('cleanup_count', 0)} æ¬¡æ¸…ç†")
        if skipped > 0:
            print(f"   â„¹ï¸ è·³è¿‡ {skipped} ä¸ªè§†é¢‘ï¼ˆå¯èƒ½è¢«å…¶ä»–ç”µè„‘å¤„ç†ï¼‰")
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        try:
            print("ğŸš€ ç»¼åˆè§†é¢‘å¤„ç†å™¨ - ç»ˆæç‰ˆ")
            print(f"   å¤„ç†æ¨¡å¼: {self.mode.value}")
            print(f"   ç¡¬ä»¶ç¼–ç : {self.hardware_info['encoder_type']}")
            print(f"   å¹¶è¡Œæ•°é‡: {self.hardware_info['max_parallel']}")
            print(f"   ç¼“å­˜: {'å¯ç”¨' if ENABLE_CACHE else 'ç¦ç”¨'}")
            print(f"   æ•°æ®åº“: {'å¯ç”¨' if self.db_manager.is_enabled else 'ç¦ç”¨'}")
            print()
            
            # éªŒè¯é…ç½®
            if not os.path.exists(FFMPEG_PATH):
                raise ValueError(f"FFmpegè·¯å¾„ä¸å­˜åœ¨: {FFMPEG_PATH}")
            if not os.path.exists(INPUT_DIR):
                raise ValueError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_DIR}")
            
            # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
            print("ğŸ” æœç´¢è§†é¢‘æ–‡ä»¶...")
            video_files = self.find_video_files(INPUT_DIR)
            
            if not video_files:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„è§†é¢‘æ–‡ä»¶")
                return
            
            print(f"âœ… æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
            
            # è®¾ç½®ROIï¼ˆå¦‚æœéœ€è¦ï¼‰
            roi = self.setup_roi_for_crop_mode(video_files)
            
            # è¿‡æ»¤è§†é¢‘æ–‡ä»¶
            print("ğŸ”§ è¿‡æ»¤è§†é¢‘æ–‡ä»¶...")
            filtered_files = self.filter_videos(video_files)
            
            if not filtered_files:
                print("âœ… æ‰€æœ‰è§†é¢‘éƒ½å·²å¤„ç†å®Œæˆï¼")
                return
            
            print(f"ğŸ“‹ å¾…å¤„ç†è§†é¢‘: {len(filtered_files)} ä¸ª")
            
            # å¼€å§‹æ‰¹é‡å¤„ç†
            print("ğŸ¬ å¼€å§‹æ‰¹é‡å¤„ç†...")
            self.process_batch(filtered_files, roi)
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            stats = self.progress_manager.get_statistics()
            print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"   å·²å®Œæˆ: {stats['completed']}")
            print(f"   å¤„ç†ä¸­: {stats['processing']}")
            print(f"   å¤±è´¥: {stats['failed']}")
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
            logger.info("ç”¨æˆ·ä¸­æ–­å¤„ç†")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
            logger.error(f"ç¨‹åºå¼‚å¸¸: {e}", exc_info=True)
        finally:
            # æ¸…ç†èµ„æº
            if hasattr(self, 'pipeline_manager'):
                self.pipeline_manager.shutdown()
            logger.info("ç¨‹åºç»“æŸ")

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ä¿¡å·å¤„ç†å™¨
    def signal_handler(signum, frame):
        logger.info("æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨æ¸…ç†...")
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œå¤„ç†å™¨
        processor = UnifiedVideoProcessor()
        processor.run()
        
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºå¼‚å¸¸: {e}", exc_info=True)
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")

if __name__ == '__main__':
    main()


